{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "### install gurobi\n",
    "from gurobipy import *\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "import interpret\n",
    "import mosek\n",
    "from interpret import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.fetch_california_housing()\n",
    "X, y = dataset.data, dataset.target  # pylint: disable=no-member\n",
    "X = pd.DataFrame(X,columns = dataset.feature_names)\n",
    "\n",
    "X['y'] = y\n",
    "y = X['y']\n",
    "X.drop('y', axis = 1, inplace = True)\n",
    "\n",
    "features = dataset.feature_names\n",
    "#X =  preprocessing.scale(X)\n",
    "#y =  preprocessing.scale(y)\n",
    "X = pd.DataFrame(X,columns = features)\n",
    "xTrain, xTest, yTrain, yTest = sklearn.model_selection.train_test_split(X,y,test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diamonds Dataset\n",
    "dataset =  pd.read_csv('diamonds.csv')\n",
    "dataset = dataset.sample(1000)\n",
    "dataset.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "y = dataset['price']\n",
    "X = dataset.drop('price',axis = 1)\n",
    "X = pd.get_dummies(X)\n",
    "features = X.columns\n",
    "X = preprocessing.scale(X)\n",
    "y =  preprocessing.scale(y)\n",
    "X = pd.DataFrame(X,columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X, y = dataset.data, dataset.target  # pylint: disable=no-member\n",
    "X = pd.DataFrame(X,columns = dataset.feature_names)\n",
    "features = dataset.feature_names\n",
    "for col in random.sample(list(X.columns),3):\n",
    "    new_col = col +'corr'\n",
    "    X[new_col] = X[col] + np.random.normal(0,np.std(X[col]),len(X))\n",
    "    features = np.append(features,new_col)\n",
    "X = preprocessing.scale(X)\n",
    "y =  preprocessing.scale(y)\n",
    "X = pd.DataFrame(X,columns = features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosted_sparse_rf(arg):\n",
    "    \n",
    "    xTrain = arg[0]\n",
    "    yTrain = arg[1]\n",
    "    \n",
    "    xTest= arg[2]\n",
    "    yTest= arg[3]\n",
    "    num_trees= arg[4]\n",
    "    colsample_by_tree= arg[5]\n",
    "    max_depth= arg[6]\n",
    "    lambd= arg[7]\n",
    "    threshold= arg[8]\n",
    "    use_indicators= arg[9]\n",
    "    col_subsample_split= arg[10]\n",
    "    n_estimators= arg[11]\n",
    "    \n",
    "    \n",
    "    train = xTrain.copy()\n",
    "    train['yTrain'] = yTrain\n",
    "    feature_list = xTrain.columns\n",
    "    nfeatures = len(feature_list)\n",
    "\n",
    "    importance_key = pd.DataFrame(feature_list,columns = ['Features'])\n",
    "\n",
    "    t_start = time.time()\n",
    "### Build Trees\n",
    "    tree_results = []\n",
    "    i = 0\n",
    "    to_sample = round(colsample_by_tree*nfeatures)\n",
    "    while i < num_trees:\n",
    "      #train each tree on bootstrapped data\n",
    "        train1 = train.sample(n = len(train), replace = True)\n",
    "        features = random.sample(list(feature_list),to_sample)\n",
    "        \n",
    "        yTrain1 = train1['yTrain']\n",
    "        xTrain1 = train1[features]\n",
    "        gbt = GradientBoostingRegressor(learning_rate = 1.0,max_depth = max_depth,n_estimators = n_estimators).fit(xTrain1,yTrain1)\n",
    "        \n",
    "        for clf1 in gbt.estimators_:\n",
    "            clf = clf1[0]\n",
    "            imp = pd.DataFrame(np.column_stack((xTrain1.columns,clf.feature_importances_)), columns = ['Features','Importances'])\n",
    "            used = imp[imp['Importances']>0]['Features'].values\n",
    "            feature_indicator = [int(x in used) for x in feature_list]\n",
    "            pred = clf.predict(xTrain[features])\n",
    "            feature_importances = pd.merge(importance_key,imp, on = 'Features', how = 'left').fillna(0)['Importances'].values\n",
    "            test_pred = clf.predict(xTest[features])\n",
    "            tree_results.append([pred,feature_indicator,feature_importances, test_pred  ,clf,xTrain1,yTrain1,features])\n",
    "            \n",
    "        i = i+1\n",
    "    t_trees = time.time()\n",
    "    print('tree building time: ' ,t_trees-t_start)\n",
    "    \n",
    "    \n",
    "### Lasso Step To Select Features\n",
    "    tree_pred = np.transpose(np.array([np.array(row[0]) for row in tree_results]))\n",
    "    test_pred = np.transpose(np.array([np.array(row[3]) for row in tree_results]))\n",
    "    indicators = np.transpose(np.array([np.array(row[1]) for row in tree_results]))\n",
    "    \n",
    "    w = cp.Variable(num_trees*n_estimators,nonneg=True)\n",
    "\n",
    "    \n",
    "    if use_indicators == True:\n",
    "        objective = 0.5 * (1/len(yTrain))*cp.sum_squares(cp.matmul(tree_pred,w)-yTrain) + lambd*cp.norm(cp.matmul(indicators,w),1)\n",
    "    if use_indicators == False:\n",
    "        objective = 0.5  * (1/len(yTrain))* cp.sum_squares(cp.matmul(tree_pred,w)-yTrain) + lambd*cp.norm(w,1)\n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(objective) )\n",
    "    prob.solve(solver = cp.MOSEK )\n",
    "    weights = np.asarray(w.value)\n",
    "    low_values_flags = np.abs(weights) < threshold  # Where values are low\n",
    "    weights[low_values_flags] = 0 \n",
    "\n",
    "### Refit Least Squares to get Weights\n",
    "\n",
    "    tree_ind = np.where(weights >0)[0]\n",
    "    \n",
    "    tree_ind = np.where(weights >0)[0]\n",
    "    if len(tree_ind)==0:\n",
    "        train_error =  np.sqrt(np.mean((yTrain )**2))\n",
    "        test_error = np.sqrt(np.mean((yTest )**2))\n",
    "        return([[],test_error,0,train_error])\n",
    "    \n",
    "    \n",
    "    tree_pred_non_zero = np.array([np.array(row[tree_ind]) for row in tree_pred])\n",
    "    test_pred_non_zero = np.array([np.array(row[tree_ind]) for row in test_pred])\n",
    "\n",
    "    final_tree_weights = cp.Variable(len(tree_ind), nonneg = True)\n",
    "    objective_final = cp.sum_squares(cp.matmul(tree_pred_non_zero,final_tree_weights)-yTrain) \n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(objective_final))\n",
    "    prob.solve(solver = cp.MOSEK)\n",
    "    \n",
    "    t_solve = time.time()\n",
    "    print('time optimization: ' ,t_solve - t_trees)\n",
    "    \n",
    "### Return Train/Test Predictions \n",
    "    final_train_pred = tree_pred_non_zero@final_tree_weights.value\n",
    "    final_test_pred = test_pred_non_zero@final_tree_weights.value\n",
    "\n",
    "### Return Feature Importances\n",
    "    importances = np.array([np.array(row[2]) for row in tree_results])\n",
    "    feature_importances = pd.DataFrame(np.column_stack((feature_list, np.transpose(importances[tree_ind])@np.abs(final_tree_weights.value))),columns = ['Features','Importances']).sort_values('Importances',ascending = False)\n",
    "    feature_importances['Importances'] = feature_importances['Importances']/sum(feature_importances['Importances'])\n",
    "    nonzero_features = sum(feature_importances['Importances']!= 0)\n",
    "### Return Accuracies\n",
    "    train_error =  np.sqrt(np.mean((yTrain -final_train_pred)**2))\n",
    "    test_error = np.sqrt(np.mean((yTest -final_test_pred)**2))\n",
    "\n",
    "    return([feature_importances,test_error,nonzero_features,train_error])\n",
    "\n",
    "\n",
    "def sparse_rf(arg):\n",
    "    \n",
    "    xTrain = arg[0]\n",
    "    yTrain = arg[1]\n",
    "    xTest= arg[2]\n",
    "    yTest= arg[3]\n",
    "    num_trees= arg[4]\n",
    "    colsample_by_tree= arg[5]\n",
    "    max_depth= arg[6]\n",
    "    lambd= arg[7]\n",
    "    threshold= arg[8] \n",
    "    use_indicators= arg[9]\n",
    "    col_subsample_split= arg[10]\n",
    "    \n",
    "    \n",
    "    train = xTrain.copy()\n",
    "    train['yTrain'] = yTrain\n",
    "    feature_list = xTrain.columns\n",
    "    nfeatures = len(feature_list)\n",
    "\n",
    "    importance_key = pd.DataFrame(feature_list,columns = ['Features'])\n",
    "\n",
    "### Build Trees\n",
    "    tree_results = []\n",
    "    i = 0\n",
    "    to_sample = round(colsample_by_tree*nfeatures)\n",
    "    print(to_sample)\n",
    "    while i < num_trees:\n",
    "      #train each tree on bootstrapped data\n",
    "        train1 = train.sample(n = len(train), replace = True)\n",
    "        features = random.sample(list(feature_list),to_sample)\n",
    "        \n",
    "        yTrain1 = train1['yTrain']\n",
    "        xTrain1 = train1[features]\n",
    "        \n",
    "        clf = DecisionTreeRegressor(max_depth = max_depth,max_features = col_subsample_split).fit(xTrain1,yTrain1)\n",
    "        imp = pd.DataFrame(np.column_stack((xTrain1.columns,clf.feature_importances_)), columns = ['Features','Importances'])\n",
    "        used = imp[imp['Importances']>0]['Features'].values\n",
    "        feature_indicator = [int(x in used) for x in feature_list]\n",
    "        pred = clf.predict(xTrain[features])\n",
    "        feature_importances = pd.merge(importance_key,imp, on = 'Features', how = 'left').fillna(0)['Importances'].values\n",
    "        test_pred = clf.predict(xTest[features])\n",
    "        tree_results.append([pred,feature_indicator,feature_importances, test_pred  ,clf,xTrain1,yTrain1,features])\n",
    "        i = i+1\n",
    "\n",
    "### Lasso Step To Select Features\n",
    "    tree_pred = np.transpose(np.array([np.array(row[0]) for row in tree_results]))\n",
    "    test_pred = np.transpose(np.array([np.array(row[3]) for row in tree_results]))\n",
    "    indicators = np.transpose(np.array([np.array(row[1]) for row in tree_results]))\n",
    "    w = cp.Variable(num_trees,nonneg=True)\n",
    "  \n",
    "\n",
    "    if use_indicators == True:\n",
    "        objective = 0.5 * (1/len(yTrain))*cp.sum_squares(cp.matmul(tree_pred,w)-yTrain) + lambd*cp.norm(cp.matmul(indicators,w),1)\n",
    "    if use_indicators == False:\n",
    "        objective = 0.5  * (1/len(yTrain))* cp.sum_squares(cp.matmul(tree_pred,w)-yTrain) + lambd*cp.norm(w,1)\n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(objective) )\n",
    "    prob.solve(solver = cp.MOSEK )\n",
    "    weights = np.asarray(w.value)\n",
    "    low_values_flags = np.abs(weights) < threshold  # Where values are low\n",
    "    weights[low_values_flags] = 0 \n",
    "\n",
    "### Refit Least Squares to get Weights\n",
    "\n",
    "    tree_ind = np.where(weights >0)[0]\n",
    "    if len(tree_ind)==0:\n",
    "        train_error =  np.sqrt(np.mean((yTrain )**2))\n",
    "        test_error = np.sqrt(np.mean((yTest )**2))\n",
    "        return([[],test_error,0,train_error])\n",
    "    \n",
    "    \n",
    "    tree_pred_non_zero = np.array([np.array(row[tree_ind]) for row in tree_pred])\n",
    "    test_pred_non_zero = np.array([np.array(row[tree_ind]) for row in test_pred])\n",
    "\n",
    "    final_tree_weights = cp.Variable(len(tree_ind), nonneg = True)\n",
    "\n",
    "    objective_final = cp.sum_squares(cp.matmul(tree_pred_non_zero,final_tree_weights)-yTrain) \n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(objective_final))\n",
    "    prob.solve(solver = cp.MOSEK)\n",
    "\n",
    "### Return Train/Test Predictions \n",
    "    final_train_pred = tree_pred_non_zero@final_tree_weights.value\n",
    "    final_test_pred = test_pred_non_zero@final_tree_weights.value\n",
    "\n",
    "### Return Feature Importances\n",
    "    importances = np.array([np.array(row[2]) for row in tree_results])\n",
    "    feature_importances = pd.DataFrame(np.column_stack((feature_list, np.transpose(importances[tree_ind])@np.abs(final_tree_weights.value))),columns = ['Features','Importances']).sort_values('Importances',ascending = False)\n",
    "    feature_importances['Importances'] = feature_importances['Importances']/sum(feature_importances['Importances'])\n",
    "    nonzero_features = sum(feature_importances['Importances']!= 0)\n",
    "### Return Accuracies\n",
    "    train_error =  np.sqrt(np.mean((yTrain -final_train_pred)**2))\n",
    "    test_error = np.sqrt(np.mean((yTest -final_test_pred)**2))\n",
    "\n",
    "    return([feature_importances,test_error,nonzero_features,train_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "tree building time:  27.61836004257202\n",
      "tree building time:  27.744537115097046\n",
      "tree building time:  28.14770007133484\n",
      "time optimization:  4.110368013381958\n",
      "time optimization:  4.133250951766968\n",
      "time optimization:  3.862781047821045\n",
      "tree building time:  25.440744876861572\n",
      "tree building time:  25.83858895301819\n",
      "tree building time:  25.736445903778076\n",
      "time optimization:  4.516003847122192\n",
      "time optimization:  4.48127293586731\n",
      "time optimization:  4.430978059768677\n",
      "tree building time:  23.436295747756958\n",
      "tree building time:  23.368048906326294\n",
      "tree building time:  23.631919145584106\n",
      "time optimization:  4.4965009689331055\n",
      "time optimization:  4.44561505317688\n",
      "time optimization:  4.482402086257935\n",
      "tree building time:  23.78541374206543\n",
      "tree building time:  24.210061073303223\n",
      "tree building time:  24.672815084457397\n",
      "time optimization:  5.688565969467163\n",
      "time optimization:  5.477031946182251\n",
      "time optimization:  4.902177810668945\n",
      "tree building time:  24.754430055618286\n",
      "tree building time:  24.70767068862915\n",
      "tree building time:  24.890818119049072\n",
      "time optimization:  4.14785099029541\n",
      "time optimization:  4.333125829696655\n",
      "time optimization:  4.24857497215271\n",
      "tree building time:  28.43946123123169\n",
      "tree building time:  28.677366971969604\n",
      "tree building time:  28.70576286315918\n",
      "time optimization:  4.907032012939453\n",
      "time optimization:  5.110666036605835\n",
      "time optimization:  4.959533929824829\n",
      "tree building time:  39.27488613128662\n",
      "tree building time:  39.274203062057495\n",
      "tree building time:  39.85482311248779\n",
      "time optimization:  7.455182790756226\n",
      "time optimization:  8.094624042510986\n",
      "time optimization:  8.599574089050293\n",
      "tree building time:  44.72093105316162\n",
      "tree building time:  44.03798723220825\n",
      "tree building time:  44.57161617279053\n",
      "time optimization:  6.180462837219238\n",
      "time optimization:  6.143866777420044\n",
      "time optimization:  5.878225803375244\n",
      "tree building time:  28.812511920928955\n",
      "tree building time:  29.11737608909607\n",
      "tree building time:  28.31402325630188\n",
      "time optimization:  5.180885076522827\n",
      "time optimization:  5.076184034347534\n",
      "time optimization:  5.855052709579468\n",
      "tree building time:  35.21134829521179\n",
      "tree building time:  35.4541118144989\n",
      "tree building time:  34.837878942489624\n",
      "time optimization:  4.6651036739349365\n",
      "time optimization:  4.76860499382019\n",
      "time optimization:  4.946250915527344\n",
      "tree building time:  31.92406702041626\n",
      "tree building time:  31.54126000404358\n",
      "tree building time:  30.854336977005005\n",
      "time optimization:  3.3927152156829834\n",
      "time optimization:  3.4208409786224365\n",
      "time optimization:  3.4710798263549805\n",
      "tree building time:  31.184705018997192\n",
      "tree building time:  31.52821397781372\n",
      "tree building time:  31.62660813331604\n",
      "time optimization:  4.1946001052856445\n",
      "time optimization:  4.145230054855347\n",
      "time optimization:  4.215436935424805\n",
      "tree building time:  19.40684700012207\n",
      "time optimization:  2.175103187561035\n",
      "tree building time:  19.913318872451782\n",
      "time optimization:  5.000952243804932\n",
      "tree building time:  15.41756820678711\n",
      "time optimization:  2.6297099590301514\n",
      "tree building time:  19.775623083114624\n",
      "time optimization:  2.9696481227874756\n",
      "1616\n",
      "16\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.01\n",
      "tree building time:  30.844115018844604\n",
      "tree building time:  31.188720226287842\n",
      "tree building time:  31.477962017059326\n",
      "time optimization:  4.1303651332855225\n",
      "time optimization:  4.055503845214844\n",
      "time optimization:  4.056836128234863\n",
      "tree building time:  26.814060926437378\n",
      "tree building time:  26.636229038238525\n",
      "tree building time:  27.268084049224854\n",
      "time optimization:  3.6203391551971436\n",
      "time optimization:  3.608142137527466\n",
      "time optimization:  3.6750340461730957\n",
      "tree building time:  23.47521209716797\n",
      "tree building time:  23.696099042892456\n",
      "tree building time:  23.832887172698975\n",
      "time optimization:  3.3400566577911377\n",
      "time optimization:  3.524207830429077\n",
      "time optimization:  3.5177929401397705\n",
      "tree building time:  29.52532386779785\n",
      "tree building time:  29.609114170074463\n",
      "tree building time:  29.88571786880493\n",
      "time optimization:  4.121581792831421\n",
      "time optimization:  4.175870895385742\n",
      "time optimization:  4.20487904548645\n",
      "tree building time:  22.963900804519653\n",
      "tree building time:  22.87364101409912\n",
      "tree building time:  22.89363408088684\n",
      "time optimization:  3.092825174331665\n",
      "time optimization:  3.1093602180480957\n",
      "time optimization:  3.1720850467681885\n",
      "tree building time:  37.012487173080444\n",
      "tree building time:  37.26690912246704\n",
      "tree building time:  37.66997504234314\n",
      "time optimization:  4.558940887451172\n",
      "time optimization:  4.254178047180176\n",
      "time optimization:  4.151988983154297\n",
      "tree building time:  28.81062912940979\n",
      "tree building time:  28.615130186080933\n",
      "tree building time:  28.91598415374756\n",
      "time optimization:  4.440073013305664\n",
      "time optimization:  4.512824773788452\n",
      "time optimization:  4.404107093811035\n",
      "tree building time:  31.052038192749023\n",
      "tree building time:  31.099880933761597\n",
      "tree building time:  30.851326942443848\n",
      "time optimization:  3.865708112716675\n",
      "time optimization:  4.087975263595581\n",
      "time optimization:  4.385739088058472\n",
      "tree building time:  31.915853023529053\n",
      "tree building time:  31.503607749938965\n",
      "tree building time:  31.46645975112915\n",
      "time optimization:  3.6442019939422607\n",
      "time optimization:  3.5152971744537354\n",
      "time optimization:  3.9144110679626465\n",
      "tree building time:  27.292883157730103\n",
      "tree building time:  27.37308382987976\n",
      "tree building time:  27.159756898880005\n",
      "time optimization:  3.9801838397979736\n",
      "time optimization:  4.08895206451416\n",
      "time optimization:  4.454859018325806\n",
      "tree building time:  26.99152898788452\n",
      "tree building time:  27.618898153305054\n",
      "tree building time:  26.95718502998352\n",
      "time optimization:  3.6414599418640137\n",
      "time optimization:  3.5832629203796387\n",
      "time optimization:  3.5436959266662598\n",
      "tree building time:  25.279717206954956\n",
      "tree building time:  25.38433289527893\n",
      "tree building time:  25.4524929523468\n",
      "time optimization:  3.5183207988739014\n",
      "time optimization:  3.5094008445739746\n",
      "time optimization:  3.261000871658325\n",
      "tree building time:  16.182727098464966\n",
      "time optimization:  2.145869016647339\n",
      "tree building time:  15.858178853988647\n",
      "time optimization:  2.1586129665374756\n",
      "tree building time:  16.021569967269897\n",
      "time optimization:  2.1372880935668945\n",
      "tree building time:  15.712277173995972\n",
      "time optimization:  2.152695894241333\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.02\n",
      "tree building time:  23.55767583847046\n",
      "tree building time:  23.73512291908264\n",
      "tree building time:  23.834769010543823\n",
      "time optimization:  3.773291826248169\n",
      "time optimization:  3.688035011291504\n",
      "time optimization:  3.7471630573272705\n",
      "tree building time:  23.628742218017578\n",
      "tree building time:  23.825484037399292\n",
      "tree building time:  23.644549131393433\n",
      "time optimization:  3.6239240169525146\n",
      "time optimization:  3.660957098007202\n",
      "time optimization:  3.731245994567871\n",
      "tree building time:  23.624940156936646\n",
      "tree building time:  23.85103702545166\n",
      "tree building time:  24.13296103477478\n",
      "time optimization:  3.4754319190979004\n",
      "time optimization:  3.562682867050171\n",
      "time optimization:  3.7305259704589844\n",
      "tree building time:  23.784119129180908\n",
      "tree building time:  23.731234073638916\n",
      "tree building time:  23.824968099594116\n",
      "time optimization:  3.450878858566284\n",
      "time optimization:  3.573232889175415\n",
      "time optimization:  3.6939988136291504\n",
      "tree building time:  24.19198489189148\n",
      "tree building time:  24.087623357772827\n",
      "tree building time:  24.14526605606079\n",
      "time optimization:  3.2907629013061523\n",
      "time optimization:  3.5663418769836426\n",
      "time optimization:  3.3969008922576904\n",
      "tree building time:  23.882018089294434\n",
      "tree building time:  23.640681982040405\n",
      "tree building time:  24.02807593345642\n",
      "time optimization:  3.3280651569366455\n",
      "time optimization:  3.4611001014709473\n",
      "time optimization:  3.4709229469299316\n",
      "tree building time:  24.76123809814453\n",
      "tree building time:  24.598176956176758\n",
      "tree building time:  24.50354790687561\n",
      "time optimization:  3.491499900817871\n",
      "time optimization:  3.5721218585968018\n",
      "time optimization:  3.573267936706543\n",
      "tree building time:  23.912576913833618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree building time:  23.79308795928955\n",
      "tree building time:  23.898151874542236\n",
      "time optimization:  3.4351370334625244\n",
      "time optimization:  3.3129069805145264\n",
      "time optimization:  3.431891918182373\n",
      "tree building time:  23.941597938537598\n",
      "tree building time:  23.759690046310425\n",
      "tree building time:  24.045225381851196\n",
      "time optimization:  3.4504549503326416\n",
      "time optimization:  3.512861967086792\n",
      "time optimization:  3.431067705154419\n",
      "tree building time:  23.79546809196472\n",
      "tree building time:  23.835134983062744\n",
      "tree building time:  23.576431035995483\n",
      "time optimization:  3.5674357414245605\n",
      "time optimization:  3.6421167850494385\n",
      "time optimization:  3.5578339099884033\n",
      "tree building time:  23.66932487487793\n",
      "tree building time:  23.95070719718933\n",
      "tree building time:  23.90078377723694\n",
      "time optimization:  3.2613003253936768\n",
      "time optimization:  3.4120779037475586\n",
      "time optimization:  3.4969921112060547\n",
      "tree building time:  23.898878812789917\n",
      "tree building time:  23.798042058944702\n",
      "tree building time:  23.65147113800049\n",
      "time optimization:  3.4001569747924805\n",
      "time optimization:  3.5866539478302\n",
      "time optimization:  3.539742946624756\n",
      "tree building time:  15.44386601448059\n",
      "time optimization:  2.0536139011383057\n",
      "tree building time:  15.079848051071167\n",
      "time optimization:  2.040170192718506\n",
      "tree building time:  15.086431980133057\n",
      "time optimization:  2.090021848678589\n",
      "tree building time:  14.989742040634155\n",
      "time optimization:  2.0827250480651855\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.03\n",
      "tree building time:  23.500844955444336\n",
      "tree building time:  23.59072518348694\n",
      "tree building time:  23.900349855422974\n",
      "time optimization:  3.6740291118621826\n",
      "time optimization:  3.682001829147339\n",
      "time optimization:  3.772844076156616\n",
      "tree building time:  23.7359778881073\n",
      "tree building time:  24.027740001678467\n",
      "tree building time:  24.033059120178223\n",
      "time optimization:  3.289961099624634\n",
      "time optimization:  3.429777145385742\n",
      "time optimization:  3.458746910095215\n",
      "tree building time:  23.73919701576233\n",
      "tree building time:  24.159338235855103\n",
      "tree building time:  23.87077498435974\n",
      "time optimization:  3.2200310230255127\n",
      "time optimization:  3.3880209922790527\n",
      "time optimization:  3.45746111869812\n",
      "tree building time:  24.107218980789185\n",
      "tree building time:  23.873968839645386\n",
      "tree building time:  24.040655851364136\n",
      "time optimization:  3.477778196334839\n",
      "time optimization:  3.5162899494171143\n",
      "time optimization:  3.479660987854004\n",
      "tree building time:  24.99279284477234\n",
      "tree building time:  24.77688217163086\n",
      "tree building time:  24.56444215774536\n",
      "time optimization:  3.107409954071045\n",
      "time optimization:  3.080035924911499\n",
      "time optimization:  3.2417309284210205\n",
      "tree building time:  31.15692687034607\n",
      "tree building time:  30.92807912826538\n",
      "tree building time:  31.25132393836975\n",
      "time optimization:  3.889200210571289\n",
      "time optimization:  4.102319717407227\n",
      "time optimization:  4.094186305999756\n",
      "tree building time:  28.00312304496765\n",
      "tree building time:  27.713009119033813\n",
      "tree building time:  27.617640018463135\n",
      "time optimization:  3.2609052658081055\n",
      "time optimization:  3.992002010345459\n",
      "time optimization:  4.1753480434417725\n",
      "tree building time:  23.11892294883728\n",
      "tree building time:  22.465397834777832\n",
      "tree building time:  22.28612518310547\n",
      "time optimization:  3.029407024383545\n",
      "time optimization:  3.144381284713745\n",
      "time optimization:  3.1532418727874756\n",
      "tree building time:  18.11739683151245\n",
      "tree building time:  17.9027841091156\n",
      "tree building time:  17.907387256622314\n",
      "time optimization:  2.6518919467926025\n",
      "time optimization:  2.642570972442627\n",
      "time optimization:  2.843353033065796\n",
      "tree building time:  17.666909217834473\n",
      "tree building time:  17.58791995048523\n",
      "tree building time:  17.978203773498535\n",
      "time optimization:  2.598867893218994\n",
      "time optimization:  2.72389817237854\n",
      "time optimization:  2.7468760013580322\n",
      "tree building time:  17.852752923965454\n",
      "tree building time:  17.639214277267456\n",
      "tree building time:  17.75131106376648\n",
      "time optimization:  2.568669080734253\n",
      "time optimization:  2.6079909801483154\n",
      "time optimization:  2.7198379039764404\n",
      "tree building time:  17.88847303390503\n",
      "tree building time:  17.805014848709106\n",
      "tree building time:  17.68274712562561\n",
      "time optimization:  2.622434139251709\n",
      "time optimization:  2.770393133163452\n",
      "time optimization:  2.7395567893981934\n",
      "tree building time:  12.768187046051025\n",
      "time optimization:  1.799271821975708\n",
      "tree building time:  12.227877855300903\n",
      "time optimization:  1.8146750926971436\n",
      "tree building time:  12.355072021484375\n",
      "time optimization:  1.809995174407959\n",
      "tree building time:  14.72434401512146\n",
      "time optimization:  1.7943649291992188\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.04\n",
      "tree building time:  25.80790615081787\n",
      "tree building time:  26.012112855911255\n",
      "tree building time:  26.340951204299927\n",
      "time optimization:  3.3875229358673096\n",
      "time optimization:  3.7244911193847656\n",
      "time optimization:  3.864076614379883\n",
      "tree building time:  27.449176788330078\n",
      "tree building time:  27.37681007385254\n",
      "tree building time:  27.24220609664917\n",
      "time optimization:  4.620665073394775\n",
      "time optimization:  4.927435874938965\n",
      "time optimization:  4.764825105667114\n",
      "tree building time:  25.00695490837097\n",
      "tree building time:  25.714158058166504\n",
      "tree building time:  25.155770778656006\n",
      "time optimization:  3.2517261505126953time optimization:  \n",
      "3.234596014022827\n",
      "time optimization:  3.1981821060180664\n",
      "tree building time:  23.713926315307617\n",
      "tree building time:  23.796154737472534\n",
      "tree building time:  23.694926977157593\n",
      "time optimization:  3.0165786743164062\n",
      "time optimization:  3.153313159942627\n",
      "time optimization:  3.188689947128296\n",
      "tree building time:  22.97489309310913\n",
      "tree building time:  22.834628105163574\n",
      "tree building time:  23.06845211982727\n",
      "time optimization:  2.7190029621124268\n",
      "time optimization:  2.84948992729187\n",
      "time optimization:  2.8378660678863525\n",
      "tree building time:  23.189543962478638\n",
      "tree building time:  23.236112117767334\n",
      "tree building time:  23.594775915145874\n",
      "time optimization:  3.7157020568847656\n",
      "time optimization:  4.076250791549683\n",
      "time optimization:  4.293227910995483\n",
      "tree building time:  26.014607906341553\n",
      "tree building time:  25.86067509651184\n",
      "tree building time:  25.86210823059082\n",
      "time optimization:  3.246579885482788\n",
      "time optimization:  3.0785157680511475\n",
      "time optimization:  3.147752046585083\n",
      "tree building time:  30.429749011993408\n",
      "tree building time:  30.518445253372192\n",
      "tree building time:  31.109621047973633\n",
      "time optimization:  4.877058029174805\n",
      "time optimization:  5.02949595451355\n",
      "time optimization:  4.8312859535217285\n",
      "tree building time:  24.94522500038147\n",
      "tree building time:  24.72539210319519\n",
      "tree building time:  24.858366012573242\n",
      "time optimization:  4.683618068695068\n",
      "time optimization:  4.635477066040039\n",
      "time optimization:  4.432582855224609\n",
      "tree building time:  28.348758935928345\n",
      "tree building time:  28.684006929397583\n",
      "tree building time:  28.44046378135681\n",
      "time optimization:  2.9616057872772217\n",
      "time optimization:  3.032616138458252\n",
      "time optimization:  3.2369601726531982\n",
      "tree building time:  24.593138933181763\n",
      "tree building time:  25.214309692382812\n",
      "tree building time:  25.320436000823975\n",
      "time optimization:  3.7462570667266846\n",
      "time optimization:  3.2823193073272705\n",
      "time optimization:  2.806057929992676\n",
      "tree building time:  25.058177947998047\n",
      "tree building time:  24.755665063858032\n",
      "tree building time:  24.723628044128418\n",
      "time optimization:  3.158653974533081\n",
      "time optimization:  3.118121862411499\n",
      "time optimization:  3.1426382064819336\n",
      "tree building time:  16.251646995544434\n",
      "time optimization:  1.9723191261291504\n",
      "tree building time:  16.593631982803345\n",
      "time optimization:  2.8142542839050293\n",
      "tree building time:  13.804129123687744\n",
      "time optimization:  1.7777810096740723\n",
      "tree building time:  12.012463092803955\n",
      "time optimization:  1.7759199142456055\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.05\n",
      "tree building time:  17.04774785041809\n",
      "tree building time: tree building time:   17.336053371429443\n",
      "17.334655046463013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time optimization:  2.5985257625579834\n",
      "time optimization:  2.7466776371002197\n",
      "time optimization:  2.8030457496643066\n",
      "tree building time:  17.28218698501587\n",
      "tree building time:  17.08232092857361\n",
      "tree building time:  17.256730794906616\n",
      "time optimization:  2.5360801219940186\n",
      "time optimization:  2.627599000930786\n",
      "time optimization:  2.7655751705169678\n",
      "tree building time:  17.09459090232849\n",
      "tree building time:  17.006617784500122\n",
      "tree building time:  17.295819997787476\n",
      "time optimization:  2.500333070755005\n",
      "time optimization:  2.5594522953033447\n",
      "time optimization:  2.6740360260009766\n",
      "tree building time:  17.297914266586304\n",
      "tree building time:  16.9820339679718\n",
      "tree building time:  17.11204981803894\n",
      "time optimization:  2.5886526107788086\n",
      "time optimization:  2.6571879386901855\n",
      "time optimization:  2.604034185409546\n",
      "tree building time:  17.158362865447998\n",
      "tree building time:  17.145341873168945\n",
      "tree building time:  17.113445281982422\n",
      "time optimization:  2.598604202270508\n",
      "time optimization:  2.6018729209899902\n",
      "time optimization:  2.580469846725464\n",
      "tree building time:  17.15922498703003\n",
      "tree building time:  17.140120029449463\n",
      "tree building time:  17.17288589477539\n",
      "time optimization:  2.57149076461792\n",
      "time optimization:  2.650906801223755\n",
      "time optimization:  2.5223281383514404\n",
      "tree building time:  17.186110019683838\n",
      "tree building time:  17.31959104537964\n",
      "tree building time:  17.424690008163452\n",
      "time optimization:  2.5515451431274414\n",
      "time optimization:  2.632388114929199\n",
      "time optimization:  2.6824629306793213\n",
      "tree building time:  17.27123522758484\n",
      "tree building time:  17.3346529006958\n",
      "tree building time:  17.057045221328735\n",
      "time optimization:  2.600374937057495\n",
      "time optimization:  2.773138999938965\n",
      "time optimization:  2.712219715118408\n",
      "tree building time:  17.30054783821106\n",
      "tree building time:  16.96943426132202\n",
      "tree building time:  17.239930868148804\n",
      "time optimization:  2.5475969314575195\n",
      "time optimization:  2.4806668758392334\n",
      "time optimization:  2.559248208999634\n",
      "tree building time:  17.17932629585266\n",
      "tree building time:  17.26231288909912\n",
      "tree building time:  17.272758722305298\n",
      "time optimization:  2.5858848094940186\n",
      "time optimization:  2.5079150199890137\n",
      "time optimization:  2.696310043334961\n",
      "tree building time:  17.140079736709595tree building time:  \n",
      "16.93447184562683\n",
      "tree building time:  17.30337619781494\n",
      "time optimization:  2.6264560222625732\n",
      "time optimization:  2.648555040359497\n",
      "time optimization:  2.5448219776153564\n",
      "tree building time:  16.95692276954651\n",
      "tree building time:  17.3093318939209\n",
      "tree building time:  17.12879204750061\n",
      "time optimization:  2.488743305206299\n",
      "time optimization:  2.5707623958587646\n",
      "time optimization:  2.4232399463653564\n",
      "tree building time:  12.355697870254517\n",
      "time optimization:  1.7859420776367188\n",
      "tree building time:  11.99946904182434\n",
      "time optimization:  1.7545790672302246\n",
      "tree building time:  12.045324087142944\n",
      "time optimization:  1.7988629341125488\n",
      "tree building time:  11.97714614868164\n",
      "time optimization:  1.776413917541504\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.06\n",
      "tree building time:  24.10356378555298\n",
      "tree building time:  24.340065002441406\n",
      "tree building time:  24.417037963867188\n",
      "time optimization:  5.4364399909973145\n",
      "time optimization:  5.3026721477508545\n",
      "time optimization:  5.539411306381226\n",
      "tree building time:  27.731106996536255\n",
      "tree building time:  27.94993305206299\n",
      "tree building time:  28.00226593017578\n",
      "time optimization:  4.23513388633728\n",
      "time optimization:  4.118149042129517\n",
      "time optimization:  4.208230018615723\n",
      "tree building time:  23.865505695343018\n",
      "tree building time:  24.028167009353638\n",
      "tree building time:  23.89149522781372\n",
      "time optimization:  2.9810123443603516\n",
      "time optimization:  3.2683467864990234\n",
      "time optimization:  3.6465070247650146\n",
      "tree building time:  25.05061984062195\n",
      "tree building time:  24.894601106643677\n",
      "tree building time:  24.80418634414673\n",
      "time optimization:  3.550217866897583\n",
      "time optimization:  3.720040798187256\n",
      "time optimization:  3.4841227531433105\n",
      "tree building time:  21.70185112953186\n",
      "tree building time:  21.276700973510742\n",
      "tree building time:  21.427653312683105\n",
      "time optimization:  2.597543954849243\n",
      "time optimization:  2.6668541431427\n",
      "time optimization:  3.1134467124938965\n",
      "tree building time:  21.911293029785156\n",
      "tree building time:  21.742929935455322\n",
      "tree building time:  21.50942611694336\n",
      "time optimization:  3.0818288326263428\n",
      "time optimization:  3.216313123703003\n",
      "time optimization:  3.2855417728424072\n",
      "tree building time:  21.840905904769897\n",
      "tree building time:  21.911869049072266\n",
      "tree building time:  21.957438945770264\n",
      "time optimization:  3.358736038208008\n",
      "time optimization:  3.323791980743408\n",
      "time optimization:  3.2463748455047607\n",
      "tree building time:  24.614914894104004\n",
      "tree building time:  24.597532272338867\n",
      "tree building time:  24.811597108840942\n",
      "time optimization:  3.0816409587860107\n",
      "time optimization:  3.097759962081909\n",
      "time optimization:  3.161357879638672\n",
      "tree building time:  27.67927598953247\n",
      "tree building time:  27.587136030197144\n",
      "tree building time:  27.12891912460327\n",
      "time optimization:  2.7302510738372803\n",
      "time optimization:  2.735154867172241\n",
      "time optimization:  2.7662389278411865\n",
      "tree building time:  21.74426007270813\n",
      "tree building time:  21.8545880317688\n",
      "tree building time:  21.977064847946167\n",
      "time optimization:  4.029439926147461\n",
      "time optimization:  4.236586093902588\n",
      "time optimization:  4.394369125366211\n",
      "tree building time:  23.302457809448242\n",
      "tree building time:  22.838459014892578\n",
      "tree building time:  23.26756501197815\n",
      "time optimization:  3.5448050498962402\n",
      "time optimization:  3.499472141265869\n",
      "time optimization:  3.166024923324585\n",
      "tree building time:  21.832629919052124\n",
      "tree building time:  21.999794960021973\n",
      "tree building time:  22.236098051071167\n",
      "time optimization:  4.136549234390259time optimization: \n",
      " 4.228793144226074\n",
      "time optimization:  3.621260166168213\n",
      "tree building time:  16.116178035736084\n",
      "time optimization:  2.3327200412750244\n",
      "tree building time:  18.43326497077942\n",
      "time optimization:  2.980832099914551\n",
      "tree building time:  15.414241075515747\n",
      "time optimization:  1.8731458187103271\n",
      "tree building time:  14.869647979736328\n",
      "time optimization:  1.8117969036102295\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.07\n",
      "tree building time:  23.807023286819458tree building time: \n",
      " 23.810911893844604\n",
      "tree building time:  24.230287075042725\n",
      "time optimization:  3.398468017578125\n",
      "time optimization:  3.5268118381500244\n",
      "time optimization:  3.2771899700164795\n",
      "tree building time:  21.075595140457153\n",
      "tree building time:  tree building time: 20.979784965515137 \n",
      "21.280285835266113\n",
      "time optimization:  3.1665008068084717\n",
      "time optimization:  3.2425971031188965\n",
      "time optimization:  3.289750099182129\n",
      "tree building time:  21.762747049331665\n",
      "tree building time:  21.779168128967285\n",
      "tree building time:  22.25719118118286\n",
      "time optimization:  3.8877458572387695\n",
      "time optimization:  3.9767327308654785\n",
      "time optimization:  3.694830894470215\n",
      "tree building time:  30.94881319999695\n",
      "tree building time:  31.064531087875366\n",
      "tree building time:  30.868042945861816\n",
      "time optimization:  4.159297704696655\n",
      "time optimization:  4.125189781188965\n",
      "time optimization:  4.164385080337524\n",
      "tree building time:  27.166646718978882\n",
      "tree building time:  27.240895986557007\n",
      "tree building time:  27.215843200683594\n",
      "time optimization:  3.2970991134643555\n",
      "time optimization: time optimization:  3.3144068717956543\n",
      " 3.3904359340667725\n",
      "tree building time:  31.58124804496765\n",
      "tree building time:  31.700249671936035\n",
      "tree building time:  31.8860981464386\n",
      "time optimization:  3.835730791091919\n",
      "time optimization:  3.907376289367676\n",
      "time optimization:  3.951988935470581\n",
      "tree building time:  29.174782037734985\n",
      "tree building time:  29.0654718875885\n",
      "tree building time:  29.079885959625244\n",
      "time optimization:  4.013073205947876\n",
      "time optimization:  4.127661943435669\n",
      "time optimization:  3.9645752906799316\n",
      "tree building time:  29.019601821899414\n",
      "tree building time:  28.646950006484985\n",
      "tree building time:  29.031486988067627\n",
      "time optimization:  4.049115896224976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time optimization:  4.009690999984741\n",
      "time optimization:  4.116549968719482\n",
      "tree building time:  28.466365814208984\n",
      "tree building time:  28.777990102767944\n",
      "tree building time:  28.883518934249878\n",
      "time optimization:  4.670608997344971\n",
      "time optimization:  4.545849800109863\n",
      "time optimization:  4.566426992416382\n",
      "tree building time:  23.24778914451599\n",
      "tree building time:  23.497225046157837\n",
      "tree building time:  22.960447072982788\n",
      "time optimization:  2.8468410968780518\n",
      "time optimization:  2.924794912338257\n",
      "time optimization:  2.9540469646453857\n",
      "tree building time:  25.4162380695343\n",
      "tree building time:  25.995380878448486\n",
      "tree building time:  26.261582851409912\n",
      "time optimization:  4.220570802688599\n",
      "time optimization:  4.300202131271362\n",
      "time optimization:  4.175878047943115\n",
      "tree building time:  26.41781187057495\n",
      "tree building time:  26.04236102104187\n",
      "tree building time:  26.51422119140625\n",
      "time optimization:  3.7846739292144775\n",
      "time optimization:  3.8305578231811523\n",
      "time optimization:  3.594980001449585\n",
      "tree building time:  14.99008321762085\n",
      "time optimization:  1.7764480113983154\n",
      "tree building time:  11.951385021209717\n",
      "time optimization:  1.7420451641082764\n",
      "tree building time:  11.974624156951904\n",
      "time optimization:  1.7500989437103271\n",
      "tree building time:  12.334856033325195\n",
      "time optimization:  1.9214050769805908\n",
      "1616\n",
      "16\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.08\n",
      "tree building time:  17.51776885986328\n",
      "tree building time:  17.560700178146362\n",
      "tree building time:  17.65278697013855\n",
      "time optimization:  2.711076021194458\n",
      "time optimization:  2.7403481006622314\n",
      "time optimization:  2.893263816833496\n",
      "tree building time:  18.69793200492859\n",
      "tree building time:  18.952858686447144\n",
      "tree building time:  18.84120512008667\n",
      "time optimization:  3.1710309982299805\n",
      "time optimization:  3.0972070693969727\n",
      "time optimization:  3.085223913192749\n",
      "tree building time:  18.151839017868042\n",
      "tree building time:  18.415902137756348\n",
      "tree building time:  18.41927218437195\n",
      "time optimization:  2.918325901031494\n",
      "time optimization:  3.0593738555908203\n",
      "time optimization:  3.1142709255218506\n",
      "tree building time:  19.55665683746338\n",
      "tree building time:  19.609879970550537\n",
      "tree building time:  19.839449167251587\n",
      "time optimization:  2.9582552909851074\n",
      "time optimization:  3.0818300247192383\n",
      "time optimization:  3.1539881229400635\n",
      "tree building time:  18.064859867095947\n",
      "tree building time:  18.084694147109985\n",
      "tree building time:  17.817690134048462\n",
      "time optimization:  2.527330160140991\n",
      "time optimization:  2.547581911087036\n",
      "time optimization:  2.6764118671417236\n",
      "tree building time:  17.957062005996704\n",
      "tree building time:  17.65609908103943\n",
      "tree building time:  17.888103008270264\n",
      "time optimization:  2.669818878173828\n",
      "time optimization:  2.675832986831665\n",
      "time optimization:  2.69482421875\n",
      "tree building time:  18.413994073867798\n",
      "tree building time:  18.78121304512024\n",
      "tree building time:  18.700779914855957\n",
      "time optimization:  2.641932964324951\n",
      "time optimization:  2.5806140899658203\n",
      "time optimization:  2.723259210586548\n",
      "tree building time:  18.08939504623413\n",
      "tree building time:  17.967220783233643\n",
      "tree building time:  17.892810821533203\n",
      "time optimization:  2.5061111450195312\n",
      "time optimization:  2.6739320755004883\n",
      "time optimization:  2.567141056060791\n",
      "tree building time:  18.742302894592285\n",
      "tree building time:  19.039548873901367\n",
      "tree building time:  19.113990306854248\n",
      "time optimization:  2.614870071411133\n",
      "time optimization:  2.8946309089660645\n",
      "time optimization:  3.0154058933258057\n",
      "tree building time:  22.888147115707397\n",
      "tree building time:  22.824088096618652\n",
      "tree building time:  22.528002977371216\n",
      "time optimization:  2.6844570636749268\n",
      "time optimization:  2.718376874923706\n",
      "time optimization:  2.8383071422576904\n",
      "tree building time:  17.279508113861084\n",
      "tree building time:  17.316511869430542\n",
      "tree building time:  16.85436201095581\n",
      "time optimization:  2.649327039718628\n",
      "time optimization:  2.8497092723846436\n",
      "time optimization:  2.9059929847717285\n",
      "tree building time:  18.719017028808594\n",
      "tree building time:  18.59301471710205\n",
      "tree building time:  18.579988956451416\n",
      "time optimization:  2.862704038619995\n",
      "time optimization:  2.875385046005249\n",
      "time optimization:  2.8842079639434814\n",
      "tree building time:  12.88976001739502\n",
      "time optimization:  1.8776953220367432\n",
      "tree building time:  13.434415102005005\n",
      "time optimization:  1.9391119480133057\n",
      "tree building time:  12.845045804977417\n",
      "time optimization:  1.7852239608764648\n",
      "tree building time:  12.103338956832886\n",
      "time optimization:  1.750537395477295\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.09\n",
      "tree building time:  16.978150129318237\n",
      "tree building time:  17.079681873321533\n",
      "tree building time:  17.155617237091064\n",
      "time optimization:  2.9161720275878906\n",
      "time optimization:  2.9741950035095215\n",
      "time optimization:  2.9891700744628906\n",
      "tree building time:  17.31904101371765\n",
      "tree building time:  17.409161806106567\n",
      "tree building time:  17.549204111099243\n",
      "time optimization:  2.610980272293091\n",
      "time optimization:  2.871011257171631\n",
      "time optimization:  2.7351109981536865\n",
      "tree building time:  17.285501956939697\n",
      "tree building time:  16.94184374809265\n",
      "tree building time:  17.115628004074097\n",
      "time optimization:  2.545743942260742\n",
      "time optimization:  2.6712982654571533\n",
      "time optimization:  2.7171318531036377\n",
      "tree building time:  17.19214677810669\n",
      "tree building time:  17.067090034484863\n",
      "tree building time:  16.8541419506073\n",
      "time optimization:  2.477017879486084\n",
      "time optimization:  2.8886330127716064time optimization: \n",
      " 2.8105528354644775\n",
      "tree building time:  17.14949917793274\n",
      "tree building time:  17.146958827972412\n",
      "tree building time:  17.173099040985107\n",
      "time optimization:  2.624480724334717\n",
      "time optimization:  2.6210029125213623\n",
      "time optimization:  2.711061954498291\n",
      "tree building time:  17.27947497367859\n",
      "tree building time:  16.988922119140625\n",
      "tree building time:  17.008630752563477\n",
      "time optimization:  2.7606558799743652\n",
      "time optimization:  2.7926950454711914\n",
      "time optimization:  2.767275094985962\n",
      "tree building time:  17.09875512123108\n",
      "tree building time:  17.0844669342041\n",
      "tree building time:  17.304646968841553\n",
      "time optimization:  2.5360658168792725\n",
      "time optimization:  2.6551458835601807\n",
      "time optimization:  2.631831169128418\n",
      "tree building time:  17.977365970611572\n",
      "tree building time:  17.820508241653442\n",
      "tree building time:  17.634455919265747\n",
      "time optimization:  2.6919939517974854\n",
      "time optimization:  2.6294779777526855\n",
      "time optimization:  2.8721678256988525\n",
      "tree building time:  17.29015803337097\n",
      "tree building time:  17.469345092773438\n",
      "tree building time:  17.890022039413452\n",
      "time optimization:  2.650261163711548\n",
      "time optimization:  2.6780149936676025time optimization: \n",
      " 2.8223397731781006\n",
      "tree building time:  17.56686806678772\n",
      "tree building time:  17.59275794029236\n",
      "tree building time:  17.79868197441101\n",
      "time optimization:  2.5882270336151123\n",
      "time optimization:  2.665767192840576\n",
      "time optimization:  2.7634310722351074\n",
      "tree building time:  17.03360104560852\n",
      "tree building time:  17.32261371612549\n",
      "tree building time:  17.099388122558594\n",
      "time optimization:  2.4998128414154053\n",
      "time optimization:  2.63565731048584\n",
      "time optimization:  2.7105889320373535\n",
      "tree building time:  17.39352583885193\n",
      "tree building time:  17.206504821777344\n",
      "tree building time:  17.45707416534424\n",
      "time optimization:  2.6775012016296387\n",
      "time optimization:  2.9383039474487305\n",
      "time optimization:  2.881659984588623\n",
      "tree building time:  13.595152139663696\n",
      "time optimization:  1.9811620712280273\n",
      "tree building time:  14.26964783668518\n",
      "time optimization:  1.902143955230713\n",
      "tree building time:  17.580770015716553\n",
      "time optimization:  2.363694190979004\n",
      "tree building time:  15.916372776031494\n",
      "time optimization:  2.0782532691955566\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.1\n",
      "tree building time:  19.931194305419922\n",
      "tree building time:  20.298861980438232\n",
      "tree building time:  20.3518009185791\n",
      "time optimization:  3.317909002304077\n",
      "time optimization:  3.3666210174560547\n",
      "time optimization:  3.5248379707336426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree building time:  20.259923934936523\n",
      "tree building time:  19.96323823928833\n",
      "tree building time:  20.300339937210083\n",
      "time optimization:  2.923039197921753\n",
      "time optimization:  3.0371367931365967\n",
      "time optimization:  3.024470090866089\n",
      "tree building time:  19.973220109939575\n",
      "tree building time:  19.897050142288208\n",
      "tree building time:  20.222712755203247\n",
      "time optimization:  2.8417367935180664\n",
      "time optimization:  2.950169086456299\n",
      "time optimization:  3.042999029159546\n",
      "tree building time:  24.331885814666748\n",
      "tree building time:  24.695362091064453\n",
      "tree building time:  24.694091081619263\n",
      "time optimization:  4.227550268173218\n",
      "time optimization:  4.082211017608643\n",
      "time optimization:  4.107515811920166\n",
      "tree building time:  24.060812950134277\n",
      "tree building time:  24.01858901977539\n",
      "tree building time:  24.015777111053467\n",
      "time optimization:  2.9192140102386475\n",
      "time optimization:  2.950843095779419\n",
      "time optimization:  3.025723934173584\n",
      "tree building time:  21.354926824569702\n",
      "tree building time:  21.135901927947998\n",
      "tree building time:  21.010279893875122\n",
      "time optimization:  3.0467329025268555\n",
      "time optimization:  3.035562038421631\n",
      "time optimization:  3.191857099533081\n",
      "tree building time:  21.16589879989624\n",
      "tree building time:  21.178498029708862\n",
      "tree building time:  21.29017210006714\n",
      "time optimization:  3.163351058959961\n",
      "time optimization:  2.9969189167022705\n",
      "time optimization:  2.9996819496154785\n",
      "tree building time:  20.859800815582275\n",
      "tree building time:  20.91245698928833\n",
      "tree building time:  20.939330101013184\n",
      "time optimization:  3.072803258895874\n",
      "time optimization:  3.1006577014923096\n",
      "time optimization:  3.1732399463653564\n",
      "tree building time:  22.203264951705933\n",
      "tree building time:  22.072454929351807\n",
      "tree building time:  21.95059084892273\n",
      "time optimization:  3.2242770195007324\n",
      "time optimization:  3.229236125946045\n",
      "time optimization:  3.4605979919433594\n",
      "tree building time:  20.759639024734497\n",
      "tree building time:  20.784600257873535\n",
      "tree building time:  20.6338312625885\n",
      "time optimization:  3.1111299991607666\n",
      "time optimization:  3.1009936332702637\n",
      "time optimization:  3.19960880279541\n",
      "tree building time:  20.55514097213745\n",
      "tree building time:  20.6753351688385\n",
      "tree building time:  20.49532699584961\n",
      "time optimization:  2.860333204269409\n",
      "time optimization:  2.9753429889678955\n",
      "time optimization:  3.0171408653259277\n",
      "tree building time:  20.54821801185608\n",
      "tree building time:  20.588656902313232\n",
      "tree building time:  20.788947105407715\n",
      "time optimization:  2.961205005645752\n",
      "time optimization:  2.984734296798706\n",
      "time optimization:  2.881507635116577\n",
      "tree building time:  14.221230745315552\n",
      "time optimization:  1.9790232181549072\n",
      "tree building time:  13.787631034851074\n",
      "time optimization:  1.956427812576294\n",
      "tree building time:  13.68423080444336\n",
      "time optimization:  1.9924092292785645\n",
      "tree building time:  13.940726041793823\n",
      "time optimization:  1.965106725692749\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.11\n",
      "tree building time:  17.943251848220825\n",
      "tree building time:  18.01842498779297\n",
      "tree building time:  18.101827144622803\n",
      "time optimization:  3.3634209632873535\n",
      "time optimization:  3.2639129161834717\n",
      "time optimization:  3.39041805267334\n",
      "tree building time:  17.013381958007812\n",
      "tree building time:  17.19199514389038\n",
      "tree building time:  17.519864082336426\n",
      "time optimization:  2.6876890659332275\n",
      "time optimization:  2.705286979675293\n",
      "time optimization:  2.7091007232666016\n",
      "tree building time:  17.381187200546265\n",
      "tree building time:  17.344869136810303\n",
      "tree building time:  17.143384218215942\n",
      "time optimization:  2.7090086936950684\n",
      "time optimization:  2.6823740005493164\n",
      "time optimization:  2.7677669525146484\n",
      "tree building time:  17.35221290588379\n",
      "tree building time:  17.20862627029419\n",
      "tree building time:  17.71327805519104\n",
      "time optimization:  2.630575180053711\n",
      "time optimization:  2.6508588790893555\n",
      "time optimization:  2.6938869953155518\n",
      "tree building time:  20.39786124229431\n",
      "tree building time:  20.75142502784729\n",
      "tree building time:  20.683655977249146\n",
      "time optimization:  2.727484941482544\n",
      "time optimization:  2.7598321437835693\n",
      "time optimization:  2.737139940261841\n",
      "tree building time:  17.160876750946045\n",
      "tree building time:  17.182591915130615\n",
      "tree building time:  17.27057695388794\n",
      "time optimization:  2.658442974090576\n",
      "time optimization:  2.701992988586426\n",
      "time optimization:  2.5346832275390625\n",
      "tree building time:  17.99858784675598\n",
      "tree building time:  17.57870578765869\n",
      "tree building time:  17.939534187316895\n",
      "time optimization:  2.538774013519287\n",
      "time optimization:  2.562825918197632\n",
      "time optimization:  2.651397705078125\n",
      "tree building time:  17.130633115768433\n",
      "tree building time:  17.653902769088745\n",
      "tree building time:  17.479116916656494\n",
      "time optimization:  2.5677287578582764\n",
      "time optimization:  2.5886220932006836\n",
      "time optimization:  2.752584934234619\n",
      "tree building time:  17.27745509147644\n",
      "tree building time:  17.232383012771606\n",
      "tree building time:  17.0742027759552\n",
      "time optimization:  2.5539979934692383\n",
      "time optimization:  2.691589117050171\n",
      "time optimization:  2.6416819095611572\n",
      "tree building time:  17.30299997329712\n",
      "tree building time:  17.484047174453735\n",
      "tree building time:  17.584404945373535\n",
      "time optimization:  2.5739431381225586\n",
      "time optimization:  2.5608551502227783\n",
      "time optimization:  2.617070198059082\n",
      "tree building time:  20.61127281188965\n",
      "tree building time:  22.09270930290222\n",
      "tree building time:  22.30972695350647\n",
      "time optimization:  4.374711036682129\n",
      "time optimization:  3.1193249225616455\n",
      "time optimization:  3.04020094871521\n",
      "tree building time:  17.91174602508545\n",
      "tree building time:  17.65750026702881\n",
      "tree building time:  17.526789903640747\n",
      "time optimization:  2.5712530612945557\n",
      "time optimization:  2.658968687057495\n",
      "time optimization:  2.5257673263549805\n",
      "tree building time:  12.585569143295288\n",
      "time optimization:  1.7982850074768066\n",
      "tree building time:  13.797096967697144\n",
      "time optimization:  1.7921271324157715\n",
      "tree building time:  10893.814189910889\n",
      "time optimization:  2.5142481327056885\n",
      "tree building time:  18261.55629181862\n",
      "time optimization:  3.588473081588745\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.12\n",
      "tree building time:  25.461120128631592\n",
      "tree building time:  25.52244806289673\n",
      "tree building time:  25.7331280708313\n",
      "time optimization:  3.3059539794921875\n",
      "time optimization:  3.387529134750366\n",
      "time optimization:  3.4272758960723877\n",
      "tree building time:  25.146567821502686\n",
      "tree building time:  25.455066204071045\n",
      "tree building time:  25.357600927352905\n",
      "time optimization:  3.050750970840454\n",
      "time optimization:  3.0656728744506836\n",
      "time optimization:  3.043941020965576\n",
      "tree building time:  22.197034120559692\n",
      "tree building time:  22.10941791534424\n",
      "tree building time:  22.083874940872192\n",
      "time optimization:  3.1968679428100586\n",
      "time optimization:  3.2751681804656982\n",
      "time optimization:  3.381753921508789\n",
      "tree building time:  26.898040056228638\n",
      "tree building time:  27.695997953414917\n",
      "tree building time:  28.108017206192017\n",
      "time optimization:  4.755055904388428\n",
      "time optimization:  3.866201162338257\n",
      "time optimization:  3.784348964691162\n",
      "tree building time:  19.394168853759766\n",
      "tree building time:  19.51477599143982\n",
      "tree building time:  19.443610906600952\n",
      "time optimization:  2.936453104019165\n",
      "time optimization:  3.2352240085601807\n",
      "time optimization:  3.5268900394439697\n",
      "tree building time:  27.07761788368225\n",
      "tree building time:  26.590357303619385\n",
      "tree building time:  26.46421504020691\n",
      "time optimization:  3.091555118560791\n",
      "time optimization:  3.2492029666900635\n",
      "time optimization:  3.6026060581207275\n",
      "tree building time:  27.68618083000183\n",
      "tree building time:  27.40934705734253\n",
      "tree building time:  27.249601125717163\n",
      "time optimization:  3.3662378787994385\n",
      "time optimization:  4.780359983444214\n",
      "time optimization:  5.371241807937622\n",
      "tree building time:  25.385809898376465\n",
      "tree building time:  24.667934894561768\n",
      "tree building time:  27.1709041595459\n",
      "time optimization:  10.452682971954346\n",
      "time optimization:  10.360701084136963\n",
      "time optimization:  7.252737998962402\n",
      "tree building time:  40.617069244384766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree building time:  41.063353300094604\n",
      "tree building time:  41.58545398712158\n",
      "time optimization:  6.483083724975586\n",
      "time optimization:  7.870725870132446\n",
      "time optimization:  7.598130941390991\n",
      "tree building time:  67.95828199386597\n",
      "tree building time:  67.08506989479065\n",
      "tree building time:  67.86911678314209\n",
      "time optimization:  9.03125810623169\n",
      "time optimization:  8.165651082992554\n",
      "time optimization:  8.8020601272583\n",
      "tree building time:  95.19566321372986\n",
      "tree building time:  95.317312002182\n",
      "tree building time:  94.6806960105896\n",
      "time optimization:  10.876359939575195\n",
      "time optimization:  12.21597695350647\n",
      "time optimization:  12.461312055587769\n",
      "tree building time:  67.26687979698181\n",
      "tree building time:  68.37200379371643\n",
      "tree building time:  66.7390649318695\n",
      "time optimization:  8.33155107498169\n",
      "time optimization:  6.438456058502197\n",
      "time optimization:  6.463353157043457\n",
      "tree building time:  27.063591957092285\n",
      "time optimization:  2.81138014793396\n",
      "tree building time:  22.750438928604126\n",
      "time optimization:  3.5808520317077637\n",
      "tree building time:  28.69406294822693\n",
      "time optimization:  2.4906179904937744\n",
      "tree building time:  23.620471954345703\n",
      "time optimization:  2.1503708362579346\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.13\n",
      "tree building time:  23.162142038345337\n",
      "tree building time: tree building time:   23.396697282791138\n",
      "23.386278867721558\n",
      "time optimization:  3.402150869369507\n",
      "time optimization:  3.517458915710449\n",
      "time optimization:  3.5704097747802734\n",
      "tree building time:  23.88193416595459\n",
      "tree building time:  23.63035798072815\n",
      "tree building time:  23.832454204559326\n",
      "time optimization:  3.1398792266845703\n",
      "time optimization:  3.315701961517334\n",
      "time optimization:  3.2457799911499023\n",
      "tree building time:  23.532506227493286tree building time: tree building time:  \n",
      "23.772463083267212 \n",
      "23.705177783966064\n",
      "time optimization:  time optimization:  3.2756919860839844\n",
      "3.3004517555236816time optimization:  \n",
      "3.3142001628875732\n",
      "tree building time:  32.670814037323\n",
      "tree building time:  32.85000920295715\n",
      "tree building time:  32.92337107658386\n",
      "time optimization:  time optimization: 5.811729907989502 \n",
      "5.680247068405151\n",
      "time optimization:  5.7529449462890625\n",
      "tree building time:  31.12682604789734\n",
      "tree building time:  32.101661920547485\n",
      "tree building time:  32.59430003166199\n",
      "time optimization:  4.685423135757446\n",
      "time optimization:  5.604036092758179\n",
      "time optimization:  6.266331195831299\n",
      "tree building time:  45.393123149871826\n",
      "tree building time:  46.281583070755005\n",
      "tree building time:  46.34025502204895\n",
      "time optimization:  9.450624942779541\n",
      "time optimization:  8.074109077453613\n",
      "time optimization:  8.114670991897583\n",
      "tree building time:  59.5709171295166\n",
      "tree building time:  58.68335795402527\n",
      "tree building time:  58.02652597427368\n",
      "time optimization:  3.231367826461792\n",
      "time optimization:  3.160271167755127\n",
      "time optimization:  3.5986690521240234\n",
      "tree building time:  30.656641960144043\n",
      "tree building time:  30.214986085891724\n",
      "tree building time:  30.398792266845703\n",
      "time optimization:  time optimization: 4.291527032852173\n",
      " 4.357280969619751\n",
      "time optimization:  4.446912050247192\n",
      "tree building time:  34.8594868183136\n",
      "tree building time:  34.97974991798401\n",
      "tree building time:  36.44612789154053\n",
      "time optimization:  6.389388799667358\n",
      "time optimization:  6.3497841358184814\n",
      "time optimization:  6.197014093399048\n",
      "tree building time:  43.26861095428467\n",
      "tree building time:  43.49795317649841\n",
      "tree building time:  43.205556869506836\n",
      "time optimization:  7.954983949661255\n",
      "time optimization:  7.925609111785889\n",
      "time optimization:  8.48586392402649\n",
      "tree building time:  39.7944700717926\n",
      "tree building time:  40.71076798439026\n",
      "tree building time:  38.56275987625122\n",
      "time optimization:  4.3669188022613525\n",
      "time optimization:  4.498720169067383\n",
      "time optimization:  5.015649080276489\n",
      "tree building time:  43.24277591705322\n",
      "tree building time:  43.652703046798706\n",
      "tree building time:  42.76558208465576\n",
      "time optimization:  5.910787105560303\n",
      "time optimization:  5.761317253112793\n",
      "time optimization:  5.852357864379883\n",
      "tree building time:  21.541969060897827\n",
      "time optimization:  2.647136926651001\n",
      "tree building time:  27.988368034362793\n",
      "time optimization:  3.3491790294647217\n",
      "tree building time:  23.814167737960815\n",
      "time optimization:  3.0109951496124268\n",
      "tree building time:  20.44172430038452\n",
      "time optimization:  2.549975633621216\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.14\n",
      "tree building time:  tree building time: 24.40305805206299\n",
      " 24.401941061019897\n",
      "tree building time:  24.735326290130615\n",
      "time optimization:  4.016255855560303\n",
      "time optimization:  4.062560081481934\n",
      "time optimization:  3.8815088272094727\n",
      "tree building time:  25.242676973342896\n",
      "tree building time:  25.100404024124146\n",
      "tree building time:  25.42306113243103\n",
      "time optimization:  3.308176040649414time optimization:  \n",
      "3.2789418697357178\n",
      "time optimization:  3.3038558959960938\n",
      "tree building time:  20.82870388031006\n",
      "tree building time:  20.68422794342041\n",
      "tree building time:  21.064127922058105\n",
      "time optimization:  3.8412532806396484\n",
      "time optimization:  3.984614849090576time optimization:  \n",
      "3.7527198791503906\n",
      "tree building time:  32.21061706542969\n",
      "tree building time:  32.32924485206604\n",
      "tree building time:  32.32901620864868\n",
      "time optimization:  time optimization: 4.298529148101807 \n",
      "4.2666120529174805\n",
      "time optimization:  4.264312982559204\n",
      "tree building time:  32.18432593345642\n",
      "tree building time:  32.20324182510376\n",
      "tree building time:  32.16989493370056\n",
      "time optimization:  3.56242299079895\n",
      "time optimization:  3.555172920227051\n",
      "time optimization:  3.549487829208374\n",
      "tree building time:  23.26818299293518\n",
      "tree building time:  23.30025291442871\n",
      "tree building time:  23.547417879104614\n",
      "time optimization:  3.4496779441833496\n",
      "time optimization:  3.438443183898926\n",
      "time optimization:  3.364748954772949\n",
      "tree building time:  26.186764001846313\n",
      "tree building time:  26.17902112007141\n",
      "tree building time:  26.176978826522827\n",
      "time optimization:  2.9117519855499268\n",
      "time optimization:  2.950739860534668\n",
      "time optimization:  2.878887176513672\n",
      "tree building time:  31.228441953659058\n",
      "tree building time:  31.44658398628235\n",
      "tree building time:  31.55426287651062\n",
      "time optimization:  3.546605110168457\n",
      "time optimization:  3.7584481239318848\n",
      "time optimization:  3.677300214767456\n",
      "tree building time:  29.937551021575928\n",
      "tree building time:  29.74752902984619\n",
      "tree building time:  29.9273362159729\n",
      "time optimization:  3.150402784347534\n",
      "time optimization:  3.3451929092407227\n",
      "time optimization:  4.22264289855957\n",
      "tree building time:  37.112459897994995\n",
      "tree building time:  37.451658964157104\n",
      "tree building time:  36.8792462348938\n",
      "time optimization:  4.609016180038452\n",
      "time optimization:  4.595922946929932\n",
      "time optimization:  4.427078008651733\n",
      "tree building time:  25.577198028564453\n",
      "tree building time:  24.700541019439697\n",
      "tree building time:  25.478387117385864\n",
      "time optimization:  4.666383743286133\n",
      "time optimization:  4.702677011489868\n",
      "time optimization:  4.603392839431763\n",
      "tree building time:  28.04305410385132\n",
      "tree building time:  28.123443841934204\n",
      "tree building time:  27.98039984703064\n",
      "time optimization:  2.4630208015441895\n",
      "time optimization:  2.60249400138855\n",
      "time optimization:  2.61607027053833\n",
      "tree building time:  18.72341299057007\n",
      "time optimization:  1.7717068195343018\n",
      "tree building time:  15.501546144485474\n",
      "time optimization:  1.773982048034668\n",
      "tree building time:  18.94908595085144\n",
      "time optimization:  1.749084234237671\n",
      "tree building time:  24.874122142791748\n",
      "time optimization:  1.7436800003051758\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.15\n",
      "tree building time:  38.179494857788086\n",
      "tree building time:  38.23623585700989\n",
      "tree building time:  38.37442207336426\n",
      "time optimization: time optimization:   5.8163051605224615.869203329086304\n",
      "\n",
      "time optimization:  5.81606388092041\n",
      "tree building time:  38.039960861206055\n",
      "tree building time:  38.34342694282532\n",
      "tree building time:  38.70630884170532\n",
      "time optimization:  5.6072211265563965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time optimization:  5.92596697807312\n",
      "time optimization:  5.822253942489624\n",
      "tree building time:  38.35041308403015\n",
      "tree building time:  38.50380277633667tree building time: \n",
      " 38.656728982925415\n",
      "time optimization:  5.559797048568726\n",
      "time optimization:  5.850967168807983\n",
      "time optimization:  5.871565103530884\n",
      "tree building time:  38.73831915855408\n",
      "tree building time:  38.05130910873413\n",
      "tree building time:  38.42091679573059\n",
      "time optimization:  5.584337949752808\n",
      "time optimization:  5.85422682762146\n",
      "time optimization:  5.755281925201416\n",
      "tree building time:  38.65469527244568\n",
      "tree building time:  38.23557376861572\n",
      "tree building time:  38.52091097831726\n",
      "time optimization:  5.650888919830322\n",
      "time optimization:  5.766462087631226\n",
      "time optimization:  5.928775072097778\n",
      "tree building time:  38.30934405326843\n",
      "tree building time:  38.32943606376648\n",
      "tree building time:  38.16987919807434\n",
      "time optimization:  5.538156986236572\n",
      "time optimization:  5.858736038208008\n",
      "time optimization:  5.825897932052612\n",
      "tree building time:  38.72528409957886\n",
      "tree building time:  38.20736503601074\n",
      "tree building time:  38.3971221446991\n",
      "time optimization:  5.637466907501221\n",
      "time optimization:  5.632041931152344\n",
      "time optimization:  5.787346839904785\n",
      "tree building time:  38.703800678253174\n",
      "tree building time:  38.13838315010071\n",
      "tree building time:  38.91832709312439\n",
      "time optimization:  5.817273139953613\n",
      "time optimization:  5.651424884796143\n",
      "time optimization:  6.387056827545166\n",
      "tree building time:  74.94364905357361\n",
      "tree building time:  75.24908804893494\n",
      "tree building time:  76.4694471359253\n",
      "time optimization:  17.450913906097412\n",
      "time optimization:  17.54764485359192\n",
      "time optimization:  18.708483695983887\n",
      "tree building time:  tree building time: 94.4041690826416 \n",
      "93.89268469810486\n",
      "tree building time:  92.6390278339386\n",
      "time optimization:  14.651057243347168\n",
      "time optimization:  14.915147066116333\n",
      "time optimization:  15.108444929122925\n",
      "tree building time:  91.07086205482483\n",
      "tree building time:  91.1011610031128\n",
      "tree building time:  91.2076370716095\n",
      "time optimization:  time optimization: 14.290807008743286\n",
      " 14.071277141571045\n",
      "time optimization:  14.366581678390503\n",
      "tree building time:  2404.7599470615387\n",
      "tree building time:  2405.303850889206\n",
      "tree building time:  2405.6802349090576\n",
      "time optimization:  15.438791751861572\n",
      "time optimization:  15.534015893936157\n",
      "time optimization:  14.090173959732056\n",
      "tree building time:  45.5456268787384\n",
      "time optimization:  1.9453611373901367\n",
      "tree building time:  13.144942045211792\n",
      "time optimization:  1.9304749965667725\n",
      "tree building time:  12.789935111999512\n",
      "time optimization:  1.8570027351379395\n",
      "tree building time:  27.52717900276184\n",
      "time optimization:  6.070575952529907\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.16\n",
      "tree building time:  27.59224796295166\n",
      "tree building time:  27.848450660705566\n",
      "tree building time:  28.553689002990723\n",
      "time optimization:  3.851283073425293\n",
      "time optimization:  3.6914072036743164\n",
      "tree building time:  tree building time: 30.309214115142822 30.23348307609558\n",
      "\n",
      "tree building time:  29.889683961868286\n",
      "time optimization:  4.562585830688477\n",
      "time optimization:  time optimization:  4.6438570022583014.491201162338257\n",
      "\n",
      "tree building time:  29.5623619556427\n",
      "tree building time:  29.698133945465088\n",
      "tree building time:  29.97003698348999\n",
      "time optimization:  4.059158086776733time optimization: \n",
      " 4.112921953201294\n",
      "time optimization:  3.913999080657959\n",
      "tree building time:  29.244951963424683\n",
      "tree building time:  29.601294994354248\n",
      "tree building time:  29.93715810775757\n",
      "time optimization:  4.002573013305664\n",
      "time optimization:  3.9013919830322266\n",
      "time optimization:  3.9028329849243164\n",
      "tree building time:  29.46723699569702\n",
      "tree building time:  29.704395055770874\n",
      "tree building time:  29.564680814743042\n",
      "time optimization:  3.870105028152466\n",
      "time optimization:  3.996103048324585\n",
      "tree building time:  29.539345264434814\n",
      "tree building time:  29.58932137489319\n",
      "tree building time:  29.422971963882446\n",
      "time optimization:  3.924257755279541\n",
      "time optimization:  4.036934852600098\n",
      "time optimization:  3.9926369190216064\n",
      "tree building time:  32.87796187400818\n",
      "tree building time:  32.66283822059631\n",
      "tree building time:  32.40300107002258\n",
      "time optimization:  4.684592962265015\n",
      "time optimization:  4.769038200378418\n",
      "time optimization:  4.663343906402588\n",
      "tree building time:  42.6347119808197\n",
      "tree building time:  43.059359073638916\n",
      "tree building time:  42.99676179885864\n",
      "time optimization:  time optimization: 4.935422897338867\n",
      " 4.823072195053101\n",
      "tree building time:  29.539644718170166\n",
      "tree building time:  29.43117594718933\n",
      "tree building time:  29.79428195953369\n",
      "time optimization:  4.911474227905273\n",
      "time optimization:  4.90189003944397\n",
      "time optimization:  4.761181116104126\n",
      "tree building time:  48.73309803009033\n",
      "tree building time:  48.73455500602722\n",
      "tree building time:  48.41105628013611\n",
      "time optimization:  4.347012042999268time optimization: \n",
      " 4.418427228927612\n",
      "time optimization:  4.401893854141235\n",
      "tree building time:  36.54574990272522\n",
      "tree building time:  36.72200918197632\n",
      "tree building time:  36.87219500541687\n",
      "time optimization:  8.091623067855835\n",
      "time optimization: time optimization:  8.069547891616821\n",
      " 8.241466760635376\n",
      "tree building time:  45.427891969680786\n",
      "tree building time:  46.212873220443726\n",
      "tree building time:  46.464593172073364\n",
      "time optimization:  5.351675748825073\n",
      "time optimization:  5.760533809661865\n",
      "time optimization:  5.9433228969573975\n",
      "tree building time:  35.24176573753357\n",
      "time optimization:  2.5752341747283936\n",
      "tree building time:  28.246789932250977\n",
      "time optimization:  3.122979164123535\n",
      "tree building time:  26.933480262756348\n",
      "time optimization:  2.735482931137085\n",
      "tree building time:  28.7547550201416\n",
      "time optimization:  2.5578560829162598\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.17\n",
      "tree building time:  66.85563278198242\n",
      "tree building time:  67.29394578933716\n",
      "tree building time:  67.54513478279114\n",
      "time optimization:  7.378229141235352\n",
      "time optimization:  7.0411131381988525\n",
      "tree building time:  69.47467589378357\n",
      "tree building time:  70.78002500534058\n",
      "tree building time:  72.01460409164429\n",
      "time optimization:  9.57347297668457\n",
      "time optimization:  8.87247896194458\n",
      "tree building time:  67.01018381118774\n",
      "tree building time:  66.0010256767273\n",
      "tree building time:  67.76575803756714\n",
      "time optimization:  11.177602052688599\n",
      "time optimization:  13.30728006362915\n",
      "tree building time:  75.6594660282135\n",
      "tree building time:  75.07342100143433\n",
      "tree building time:  72.39378905296326\n",
      "time optimization:  4.535784006118774\n",
      "time optimization:  4.79886269569397\n",
      "time optimization:  5.755208969116211\n",
      "tree building time:  42.18559694290161\n",
      "tree building time:  42.70990800857544\n",
      "tree building time:  42.21638107299805\n",
      "time optimization:  7.75164008140564\n",
      "time optimization:  7.903443813323975\n",
      "time optimization:  6.992645025253296\n",
      "tree building time:  29.96738314628601\n",
      "tree building time:  28.93384289741516\n",
      "tree building time:  29.14793300628662\n",
      "time optimization:  3.4136199951171875\n",
      "time optimization:  3.588052988052368\n",
      "time optimization:  3.509424924850464\n",
      "tree building time:  23.924027681350708\n",
      "tree building time:  23.812974214553833\n",
      "tree building time:  23.86446499824524\n",
      "time optimization:  3.6803929805755615\n",
      "time optimization:  4.133980751037598\n",
      "tree building time:  29.432268857955933\n",
      "tree building time:  29.13292407989502\n",
      "tree building time:  29.280977725982666\n",
      "time optimization:  3.7094199657440186\n",
      "time optimization:  3.9456639289855957\n",
      "time optimization:  4.1351470947265625\n",
      "tree building time:  25.095940113067627\n",
      "tree building time:  24.86461305618286\n",
      "tree building time:  24.555917024612427\n",
      "time optimization:  3.3475117683410645\n",
      "time optimization:  3.392740249633789\n",
      "time optimization:  3.4911539554595947\n",
      "tree building time:  24.546270847320557\n",
      "tree building time:  24.427141904830933\n",
      "tree building time:  24.187819957733154\n",
      "time optimization:  3.3655600547790527\n",
      "time optimization:  3.482278823852539\n",
      "time optimization:  3.351215124130249\n",
      "tree building time:  24.079840898513794\n",
      "tree building time:  23.983582019805908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree building time:  23.87719202041626\n",
      "time optimization:  3.3142499923706055\n",
      "time optimization:  3.683398723602295\n",
      "time optimization:  3.648286819458008\n",
      "tree building time:  25.004841804504395\n",
      "tree building time:  24.424540996551514\n",
      "tree building time:  24.802557945251465\n",
      "time optimization:  3.3363072872161865\n",
      "time optimization:  3.313513994216919\n",
      "time optimization:  3.3466780185699463\n",
      "tree building time:  13.699718952178955\n",
      "time optimization:  1.9336729049682617\n",
      "tree building time:  -177.34158372879028\n",
      "time optimization:  1.9363219738006592\n",
      "tree building time:  13.345959901809692\n",
      "time optimization:  1.900813102722168\n",
      "tree building time:  17.726534843444824\n",
      "time optimization:  2.7672131061553955\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.18\n",
      "tree building time:  25.503488063812256\n",
      "tree building time:  25.852779865264893\n",
      "tree building time:  25.995037078857422\n",
      "time optimization:  3.8709778785705566\n",
      "tree building time:  28.486593008041382\n",
      "tree building time:  28.14268183708191\n",
      "tree building time:  28.154356241226196\n",
      "time optimization:  3.5370101928710938\n",
      "time optimization:  3.8433609008789062\n",
      "time optimization:  3.680999994277954\n",
      "tree building time:  27.393380165100098\n",
      "tree building time:  27.127044916152954\n",
      "tree building time:  27.456305980682373\n",
      "time optimization:  3.5794999599456787\n",
      "time optimization:  3.576639175415039\n",
      "tree building time:  27.34573793411255\n",
      "tree building time:  27.84863781929016\n",
      "tree building time:  27.656575918197632\n",
      "tree building time:  27.581175088882446\n",
      "tree building time:  27.477980852127075\n",
      "tree building time:  27.972925186157227\n",
      "time optimization:  3.6155619621276855\n",
      "time optimization:  3.878558874130249\n",
      "tree building time:  26.009591102600098\n",
      "tree building time:  25.609161853790283\n",
      "tree building time:  25.64134407043457\n",
      "time optimization:  3.5146260261535645\n",
      "time optimization:  3.518216133117676\n",
      "time optimization:  3.7832109928131104\n",
      "tree building time:  28.74203634262085\n",
      "tree building time:  29.04914617538452\n",
      "tree building time:  30.030431032180786\n",
      "time optimization:  4.566637754440308\n",
      "time optimization:  4.615559816360474\n",
      "time optimization:  4.295907735824585\n",
      "tree building time:  29.50649905204773tree building time: \n",
      " 29.651808977127075\n",
      "tree building time:  28.75230884552002\n",
      "time optimization:  3.55539608001709\n",
      "tree building time:  26.557629823684692\n",
      "tree building time:  26.842634916305542\n",
      "tree building time:  26.56298804283142\n",
      "time optimization:  3.522731065750122\n",
      "time optimization:  3.6898181438446045\n",
      "time optimization:  3.9801993370056152\n",
      "tree building time:  27.228084087371826\n",
      "tree building time:  27.19143509864807\n",
      "tree building time:  26.914294958114624\n",
      "time optimization:  3.3907487392425537\n",
      "tree building time:  27.429896116256714\n",
      "tree building time:  27.592987775802612\n",
      "tree building time:  27.356789112091064\n",
      "time optimization:  3.878495216369629\n",
      "time optimization:  4.141331911087036\n",
      "tree building time:  26.087082386016846\n",
      "tree building time:  26.161077737808228\n",
      "tree building time:  25.92951798439026\n",
      "time optimization:  3.0695319175720215\n",
      "tree building time:  14.502087354660034\n",
      "time optimization:  1.897115707397461\n",
      "tree building time:  13.563638925552368\n",
      "time optimization:  2.1663501262664795\n",
      "tree building time:  13.858117818832397\n",
      "tree building time:  13.650673866271973\n",
      "time optimization:  1.9949209690093994\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.19\n",
      "tree building time:  25.499181032180786\n",
      "tree building time:  25.534154891967773\n",
      "tree building time:  26.001440048217773\n",
      "time optimization:  3.631624937057495\n",
      "tree building time:  30.1875581741333\n",
      "tree building time:  30.536250114440918\n",
      "tree building time:  30.12365961074829\n",
      "time optimization:  4.143428802490234\n",
      "time optimization:  4.053653955459595\n",
      "time optimization:  4.272600173950195\n",
      "tree building time:  27.646636724472046\n",
      "tree building time:  27.746305227279663\n",
      "tree building time:  27.62183904647827\n",
      "time optimization:  3.2482571601867676\n",
      "tree building time:  25.68738293647766\n",
      "tree building time:  25.45978808403015\n",
      "tree building time:  25.96164298057556\n",
      "tree building time:  28.726752042770386\n",
      "tree building time:  29.291474103927612\n",
      "tree building time:  29.146714210510254\n",
      "time optimization:  4.0408618450164795\n",
      "tree building time:  30.490229845046997\n",
      "tree building time:  31.206074714660645\n",
      "tree building time:  30.95995593070984\n",
      "time optimization:  3.8110129833221436\n",
      "time optimization:  3.62739896774292\n",
      "tree building time:  26.765403032302856\n",
      "tree building time:  27.119697093963623\n",
      "tree building time:  27.08289623260498\n",
      "time optimization:  3.894382953643799\n",
      "time optimization:  3.9637889862060547\n",
      "tree building time:  25.463942050933838\n",
      "tree building time:  25.881330966949463\n",
      "tree building time:  25.79431915283203\n",
      "time optimization:  3.233690023422241\n",
      "time optimization:  3.421046018600464\n",
      "tree building time:  26.84151601791382\n",
      "tree building time:  26.220930099487305\n",
      "tree building time:  26.320904970169067\n",
      "tree building time:  26.51513385772705\n",
      "tree building time:  26.50739097595215\n",
      "tree building time:  26.674827814102173\n",
      "time optimization:  3.7832140922546387\n",
      "time optimization:  3.704482078552246\n",
      "tree building time:  26.470200061798096\n",
      "tree building time:  26.46951198577881\n",
      "tree building time:  26.431333780288696\n",
      "time optimization:  3.497565984725952\n",
      "time optimization:  3.6943821907043457\n",
      "tree building time:  28.69869899749756\n",
      "tree building time:  29.20729899406433\n",
      "tree building time:  28.96754217147827\n",
      "time optimization:  3.1441359519958496\n",
      "time optimization:  3.2928860187530518\n",
      "tree building time:  14.421133041381836\n",
      "time optimization:  2.0309150218963623\n",
      "tree building time:  14.064349174499512\n",
      "time optimization:  1.9908111095428467\n",
      "tree building time:  14.199903964996338\n",
      "tree building time:  14.156625032424927\n",
      "time optimization:  1.9570660591125488\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.2\n",
      "tree building time:  25.17401909828186\n",
      "tree building time:  25.891133069992065\n",
      "tree building time:  26.15847110748291\n",
      "time optimization:  3.5081729888916016\n",
      "time optimization:  3.6345231533050537\n",
      "tree building time:  26.542135000228882\n",
      "tree building time:  26.250704050064087\n",
      "tree building time:  26.799285888671875\n",
      "time optimization:  3.6705100536346436\n",
      "tree building time:  27.037904024124146\n",
      "tree building time:  26.819123029708862\n",
      "tree building time:  26.88107204437256\n",
      "time optimization:  3.599148750305176\n",
      "tree building time:  28.631991147994995\n",
      "tree building time:  28.903121948242188\n",
      "tree building time:  28.48007321357727\n",
      "time optimization:  3.255812168121338\n",
      "tree building time:  27.551361799240112\n",
      "tree building time:  27.150954961776733\n",
      "tree building time:  27.083622694015503\n",
      "tree building time:  28.899012088775635\n",
      "tree building time:  28.858333110809326\n",
      "tree building time:  29.03771185874939\n",
      "tree building time:  25.76798367500305\n",
      "tree building time:  25.40565514564514\n",
      "tree building time:  26.089942693710327\n",
      "time optimization:  3.5117831230163574\n",
      "time optimization:  3.648709297180176\n",
      "tree building time:  26.25234889984131\n",
      "tree building time:  26.341336965560913\n",
      "tree building time:  26.405745029449463\n",
      "time optimization:  3.512946128845215\n",
      "tree building time:  26.93169093132019\n",
      "tree building time:  27.440916299819946\n",
      "tree building time:  27.378281116485596\n",
      "time optimization:  3.497109889984131\n",
      "tree building time:  25.521445751190186\n",
      "tree building time:  25.545961141586304\n",
      "tree building time:  25.262474060058594\n",
      "time optimization:  3.429141044616699\n",
      "tree building time:  24.547807931900024\n",
      "tree building time:  24.295299768447876\n",
      "tree building time:  23.90046215057373\n",
      "tree building time:  24.427812814712524\n",
      "tree building time:  24.442182064056396\n",
      "tree building time:  24.384681940078735\n",
      "tree building time:  15.266385793685913\n",
      "time optimization:  1.901686191558838\n",
      "tree building time:  13.148190021514893\n",
      "tree building time:  13.256792068481445\n",
      "tree building time:  13.480376958847046\n",
      "161616\n",
      "\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree building time:  24.41593027114868\n",
      "tree building time:  24.76140809059143\n",
      "tree building time:  25.317718029022217\n",
      "time optimization:  3.429257869720459\n",
      "time optimization:  3.5111160278320312\n",
      "tree building time:  26.076697826385498\n",
      "tree building time:  26.036064863204956\n",
      "tree building time:  26.029800176620483\n",
      "time optimization:  3.5320632457733154\n",
      "tree building time:  25.87661600112915\n",
      "tree building time:  25.527158737182617\n",
      "tree building time:  25.63583993911743\n",
      "tree building time:  25.427321672439575\n",
      "tree building time:  25.69548201560974\n",
      "tree building time:  25.23875880241394\n",
      "time optimization:  3.790086269378662\n",
      "tree building time:  24.89807105064392\n",
      "tree building time:  24.968641757965088\n",
      "tree building time:  25.113160133361816\n",
      "tree building time:  28.215285778045654\n",
      "tree building time:  28.223285913467407\n",
      "tree building time:  28.636937141418457\n",
      "time optimization:  3.510915994644165\n",
      "tree building time:  24.90096092224121\n",
      "tree building time:  25.174143075942993\n",
      "tree building time:  25.15962815284729\n",
      "tree building time:  26.678695917129517\n",
      "tree building time:  26.230255842208862\n",
      "tree building time:  26.630285024642944\n",
      "time optimization:  3.597332239151001\n",
      "time optimization:  3.453856945037842\n",
      "tree building time:  26.094615697860718\n",
      "tree building time:  25.623850107192993\n",
      "tree building time:  25.888614892959595\n",
      "tree building time:  25.754465103149414\n",
      "tree building time:  25.2846360206604\n",
      "tree building time:  25.568377017974854\n",
      "time optimization:  3.4853110313415527\n",
      "tree building time:  25.520421028137207\n",
      "tree building time:  25.83453392982483\n",
      "tree building time:  25.727009773254395\n",
      "time optimization:  3.281691074371338\n",
      "tree building time:  24.682594060897827\n",
      "tree building time:  25.132653951644897\n",
      "tree building time:  24.669121026992798\n",
      "time optimization:  3.875138759613037\n",
      "tree building time:  13.478389024734497\n",
      "tree building time:  13.712699174880981\n",
      "tree building time:  14.915957927703857\n",
      "tree building time:  13.672664165496826\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.22\n",
      "tree building time: tree building time:   24.8645360469818124.866389989852905\n",
      "\n",
      "tree building time:  25.096151113510132\n",
      "tree building time:  25.7522029876709\n",
      "tree building time:  25.902325868606567\n",
      "tree building time:  25.86658525466919\n",
      "tree building time:  26.52058482170105\n",
      "tree building time:  26.367259740829468\n",
      "tree building time:  26.577937841415405\n",
      "time optimization:  3.4948182106018066\n",
      "tree building time:  25.557169914245605\n",
      "tree building time:  25.35082721710205\n",
      "tree building time:  26.151418209075928\n",
      "tree building time:  27.184679985046387\n",
      "tree building time:  27.244330883026123\n",
      "tree building time:  27.58903408050537\n",
      "time optimization:  3.648822069168091\n",
      "tree building time:  25.795758962631226\n",
      "tree building time:  26.562019109725952\n",
      "tree building time:  26.027749061584473\n",
      "time optimization:  3.362070083618164\n",
      "tree building time:  26.527061939239502\n",
      "tree building time:  26.50103497505188\n",
      "tree building time:  26.393121004104614\n",
      "tree building time:  26.020432710647583\n",
      "tree building time:  25.930073976516724\n",
      "tree building time:  26.056261777877808\n",
      "tree building time:  24.835731983184814\n",
      "tree building time:  24.648869037628174\n",
      "tree building time:  24.598732948303223\n",
      "tree building time:  24.709295988082886\n",
      "tree building time:  24.372942209243774\n",
      "tree building time:  24.941410064697266\n",
      "tree building time:  25.13174819946289\n",
      "tree building time:  24.83576202392578\n",
      "tree building time:  24.777026176452637\n",
      "time optimization:  3.3147456645965576\n",
      "tree building time:  27.876832962036133\n",
      "tree building time:  27.355592012405396\n",
      "tree building time:  27.20285677909851\n",
      "time optimization:  3.380843162536621\n",
      "tree building time:  14.590394973754883\n",
      "tree building time:  14.207004070281982\n",
      "tree building time:  14.573885917663574\n",
      "tree building time:  14.107067108154297\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.23\n",
      "tree building time:  27.615785837173462\n",
      "tree building time:  27.69740915298462\n",
      "tree building time:  27.757312774658203\n",
      "time optimization:  3.9039371013641357\n",
      "tree building time:  25.32113480567932\n",
      "tree building time:  25.396080255508423\n",
      "tree building time:  25.58254885673523\n",
      "tree building time:  26.65979814529419\n",
      "tree building time:  26.881145238876343\n",
      "tree building time:  27.211561918258667\n",
      "time optimization:  3.509434700012207\n",
      "tree building time:  26.330628871917725\n",
      "tree building time:  26.32734489440918\n",
      "tree building time:  26.79274868965149\n",
      "tree building time:  25.756618976593018\n",
      "tree building time:  26.450095176696777\n",
      "tree building time:  25.66913604736328\n",
      "tree building time:  25.668959140777588\n",
      "tree building time:  25.25141477584839\n",
      "tree building time:  25.80366086959839\n",
      "time optimization:  3.4828908443450928\n",
      "tree building time:  26.643622875213623\n",
      "tree building time:  26.09711503982544\n",
      "tree building time:  26.37387204170227\n",
      "time optimization:  3.408071994781494\n",
      "tree building time:  27.938210010528564\n",
      "tree building time:  27.634282112121582\n",
      "tree building time:  27.95172905921936\n",
      "tree building time:  26.322783946990967\n",
      "tree building time:  26.081761598587036\n",
      "tree building time:  26.088478088378906\n",
      "tree building time:  24.64364790916443tree building time:  \n",
      "24.24013900756836\n",
      "tree building time:  24.175643920898438\n",
      "tree building time:  23.93869113922119\n",
      "tree building time:  24.389729976654053\n",
      "tree building time:  23.66897988319397\n",
      "tree building time:  24.225473880767822\n",
      "tree building time:  23.89873504638672\n",
      "tree building time:  24.3207848072052\n",
      "time optimization:  3.2679150104522705\n",
      "tree building time:  14.058940887451172\n",
      "time optimization:  1.8521480560302734\n",
      "tree building time:  13.261372327804565\n",
      "tree building time:  13.2501060962677\n",
      "tree building time:  13.307909965515137\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "0.24\n",
      "tree building time:  26.890524864196777\n",
      "tree building time:  26.927859783172607\n",
      "tree building time:  27.443612098693848\n",
      "tree building time:  23.72252607345581\n",
      "tree building time:  23.74119210243225\n",
      "tree building time:  23.88325023651123\n",
      "tree building time:  26.617235898971558\n",
      "tree building time:  26.95436429977417\n",
      "tree building time:  26.97935199737549\n",
      "tree building time:  30.32315683364868\n",
      "tree building time:  30.893660306930542\n",
      "tree building time:  30.647675275802612\n",
      "tree building time:  40.563199043273926\n",
      "tree building time:  40.7417778968811\n",
      "tree building time:  40.710505962371826\n",
      "time optimization:  4.472868204116821\n",
      "tree building time:  39.05317234992981\n",
      "tree building time:  39.09082531929016\n",
      "tree building time:  39.75102400779724\n",
      "tree building time:  32.23562002182007\n",
      "tree building time:  30.904379844665527\n",
      "tree building time:  31.107628107070923\n",
      "time optimization:  3.5778470039367676\n",
      "tree building time:  30.200135231018066\n",
      "tree building time:  29.580623865127563\n",
      "tree building time:  30.41758704185486\n",
      "tree building time:  28.239238739013672\n",
      "tree building time:  27.738847017288208\n",
      "tree building time:  27.700860023498535\n",
      "tree building time:  24.55512809753418\n",
      "tree building time:  24.384382963180542\n",
      "tree building time:  24.56029725074768\n",
      "tree building time:  25.268199920654297\n",
      "tree building time:  25.958740949630737\n",
      "tree building time:  25.463313102722168\n",
      "tree building time:  27.66642999649048\n",
      "tree building time:  27.84840703010559\n",
      "tree building time:  27.090087890625\n",
      "tree building time:  15.476283073425293\n",
      "tree building time:  13.30083703994751\n",
      "tree building time:  14.244447231292725\n",
      "tree building time:  13.615215063095093\n",
      "1616\n",
      "\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "### run experiment\n",
    "pool = mp.Pool(3)\n",
    "num_trees = 400\n",
    "colsample_by_tree = 1\n",
    "max_depth = 4\n",
    "col_subsample_split = 'auto'\n",
    "use_indicators = True\n",
    "threshold = 10**-3\n",
    "ntrials = 40\n",
    "n_estimators = 3\n",
    "lambdrange = np.arange(0,.25,.01)\n",
    "boost_acc1 = []\n",
    "boost_nonzero1 = []\n",
    "boost_train_error = []\n",
    "\n",
    "bag_acc1 = []\n",
    "bag_nonzero1 = []\n",
    "bag_train_error = []\n",
    "\n",
    "\n",
    "for lambd in lambdrange :\n",
    "    print(lambd)\n",
    "    trial = 0\n",
    "    result1= []\n",
    "    args = []\n",
    "    \n",
    "    \n",
    "    while trial < ntrials:\n",
    "        xTrain, xTest, yTrain, yTest = sklearn.model_selection.train_test_split(X,y,test_size = .3)\n",
    "        args.append([xTrain,yTrain,xTest,yTest,num_trees,colsample_by_tree,max_depth,lambd,threshold, use_indicators,col_subsample_split,n_estimators])\n",
    "        trial = trial + 1\n",
    "\n",
    "    result1 = pool.map(boosted_sparse_rf, args)\n",
    "    acc = [row[1] for row in result1]\n",
    "    nonzero = [row[2] for row in result1]\n",
    "    train_acc = [row[3] for row in result1]\n",
    "    \n",
    "    boost_acc1.append(acc)\n",
    "    boost_nonzero1.append(nonzero)\n",
    "    boost_train_error.append(train_acc)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    while trial < ntrials:\n",
    "        xTrain, xTest, yTrain, yTest = sklearn.model_selection.train_test_split(X,y,test_size = .3)\n",
    "        args.append([xTrain,yTrain,xTest,yTest,num_trees*n_estimators,colsample_by_tree,max_depth,lambd,threshold, use_indicators,col_subsample_split])\n",
    "        trial = trial + 1\n",
    "\n",
    "    result1 = pool.map(sparse_rf, args)\n",
    "    acc = [row[1] for row in result1]\n",
    "    nonzero = [row[2] for row in result1]\n",
    "    train_acc = [row[3] for row in result1]\n",
    "    \n",
    "    \n",
    "    bag_acc1.append(acc)\n",
    "    bag_nonzero1.append(nonzero)\n",
    "    bag_train_error.append(train_acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_ebm(xTrain,yTrain,xTest,yTest,lambd,threshold):\n",
    "\n",
    "    all_features = pd.DataFrame(xTrain.columns,columns = ['Features'])\n",
    "    ebm = ExplainableBoostingRegressor(n_jobs = 3).fit(xTrain,yTrain)\n",
    "    ebm_local = ebm.explain_local(xTrain, yTrain)\n",
    "    pred = ebm.predict(xTest)\n",
    "    \n",
    "    #print('ebm acc:',np.sqrt(np.mean((yTest -pred)**2)))\n",
    "    \n",
    "    local_imp = []\n",
    "    for i in range(0,len(yTrain)):\n",
    "        scores = ebm_local._internal_obj.get('specific')[i].get('scores')\n",
    "        local_imp.append(scores)\n",
    "\n",
    "    local_imp = np.array(local_imp)\n",
    "\n",
    "    test_imp = []\n",
    "    ebm_test = ebm.explain_local(xTest,yTest)\n",
    "    for i in range(0,len(yTest)):\n",
    "        scores = ebm_test._internal_obj.get('specific')[i].get('scores')\n",
    "        test_imp.append(scores)\n",
    "    test_imp  = np.array(test_imp)\n",
    "\n",
    "\n",
    "    #print('ebm local acc:',np.sqrt(np.mean((yTest -np.sum(test_imp,axis = 1))**2)))\n",
    "\n",
    "    w = cp.Variable(len(xTrain.columns),nonneg=True)\n",
    "\n",
    "    objective = 0.5 * (1/len(yTrain))*cp.sum_squares(cp.matmul(local_imp,w)-yTrain) + \\\n",
    "                                                    lambd*cp.norm(w,1)\n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(objective))\n",
    "    prob.solve(solver=cp.GUROBI)\n",
    "    weights = np.asarray(w.value)\n",
    "    low_values_flags = np.abs(weights) < threshold  # Where values are low\n",
    "    weights[low_values_flags] = 0 \n",
    "\n",
    "    feature_ind = np.where(weights >0)[0]\n",
    "\n",
    "    if len(feature_ind) == 0:\n",
    "        train_error =  np.sqrt(np.mean((yTrain)**2))\n",
    "        test_error = np.sqrt(np.mean((yTest)**2))\n",
    "        nonzero_features = 0\n",
    "        feature_importances = all_features\n",
    "        feature_importances['Importances'] = 0\n",
    "        return([feature_importances,test_error,nonzero_features,train_error])\n",
    "\n",
    "\n",
    "    features_sub = xTrain.columns[feature_ind]\n",
    "    train_pred_non_zero = np.array([np.array(row[feature_ind]) for row in local_imp])\n",
    "    test_pred_non_zero = np.array([np.array(row[feature_ind]) for row in test_imp])\n",
    "\n",
    "    final_tree_weights = cp.Variable(len(feature_ind), nonneg = True)\n",
    "    objective_final = cp.sum_squares(cp.matmul(train_pred_non_zero,final_tree_weights)-yTrain) \n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(objective_final))\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "\n",
    "    final_train_pred = train_pred_non_zero@final_tree_weights.value\n",
    "    final_test_pred = test_pred_non_zero@final_tree_weights.value\n",
    "\n",
    "    train_error =  np.sqrt(np.mean((yTrain -final_train_pred)**2))\n",
    "    test_error = np.sqrt(np.mean((yTest -final_test_pred)**2))\n",
    "    \n",
    "    #print('after_opt_accuracy:', test_error)\n",
    "\n",
    "    importances = np.sum(np.abs(test_pred_non_zero),axis = 0)\n",
    "    feature_importances = pd.DataFrame(np.column_stack((features_sub,importances))\\\n",
    "                                      ,columns = ['Features','Importances'])\n",
    "    feature_importances = pd.merge(all_features,feature_importances,on = 'Features',how = 'left').fillna(0).\\\n",
    "                            sort_values('Importances',ascending = False)\n",
    "    nonzero_features = len(feature_ind)\n",
    "\n",
    "    \n",
    "    return([feature_importances,test_error,nonzero_features,train_error])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_test_acc = []\n",
    "ebm_nonzero = []\n",
    "ebm_train_acc = []\n",
    "\n",
    "lambdrange = np.append(np.arange(0,.102,.002),np.arange(.0102,.25,.05))\n",
    "ntrials = 20\n",
    "threshold = 10**-3\n",
    "\n",
    "\n",
    "for lambd in lambdrange :\n",
    "    \n",
    "    trial = 0\n",
    "    result1 = []\n",
    "    args = []\n",
    "    \n",
    "    while trial < ntrials:\n",
    "        xTrain, xTest, yTrain, yTest = sklearn.model_selection.train_test_split(X,y,test_size = .3)\n",
    "        results = sparse_ebm(xTrain,yTrain,xTest,yTest,lambd,threshold)\n",
    "        result1.append(results)\n",
    "        trial = trial+1\n",
    "    \n",
    "    test_acc = [row[1] for row in result1]\n",
    "    nonzero = [row[2] for row in result1]\n",
    "    train_acc = [row[3] for row in result1]\n",
    "    \n",
    "    \n",
    "    ebm_test_acc.append(test_acc)\n",
    "    ebm_nonzero.append(nonzero)\n",
    "    ebm_train_acc.append(train_acc)\n",
    "gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.811520032816645, tolerance: 0.032268422718186265\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.42535131955441, tolerance: 0.0363564131637253\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.241446414960414, tolerance: 0.035527311454453016\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.55967155579516, tolerance: 0.03296441211323259\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.04092740642383, tolerance: 0.03725160336328329\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.781788253693875, tolerance: 0.03604372903496252\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.9015368768805, tolerance: 0.0366117889658028\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.37561916433678, tolerance: 0.03846133440520206\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.758535167873774, tolerance: 0.03484030326352644\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.28069249987509, tolerance: 0.03463601761959426\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.02694319463737, tolerance: 0.03743012199051887\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.83985430336658, tolerance: 0.03411977029443802\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.54126371001057, tolerance: 0.035816315265385104\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.526135799047715, tolerance: 0.03419136243625145\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.453297922350714, tolerance: 0.035638996322686724\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.86490721532977, tolerance: 0.034862109233212896\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.34191105766392, tolerance: 0.03562994959970265\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.485347584376896, tolerance: 0.03591096332155203\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.919942514157, tolerance: 0.03769808608124061\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.68254469512544, tolerance: 0.0311137245107097\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.98999870891234, tolerance: 0.0377621299680288\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.87224513528444, tolerance: 0.03719970024251854\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.068627669155504, tolerance: 0.03477915699703319\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.567472070843216, tolerance: 0.0368658887562085\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.956167301976436, tolerance: 0.03758176503391983\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.12360704032842, tolerance: 0.03971107833288214\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.63155486966885, tolerance: 0.035247638393124205\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.076174035442094, tolerance: 0.03741924622712413\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.63156972461263, tolerance: 0.04012218769037893\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.12603221554505, tolerance: 0.0355238940667834\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.167572572379065, tolerance: 0.03319206533786267\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.64661156847123, tolerance: 0.0376033307120002\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.57030133812193, tolerance: 0.03617500247090952\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.316182777505894, tolerance: 0.03721310263149487\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.37297855097931, tolerance: 0.035120242549617556\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.942210493440946, tolerance: 0.035218174579913705\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.696419945744935, tolerance: 0.03853848715110045\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.893739798131875, tolerance: 0.0366885636564769\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.32586198556897, tolerance: 0.03173343529126356\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.024082834209324, tolerance: 0.03475100754310354\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.867883990490725, tolerance: 0.03580380109537441\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.08019549976318, tolerance: 0.03356029380329448\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.5577077775671, tolerance: 0.038922038966409715\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.941029173306646, tolerance: 0.029819257667244792\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.62558229760802, tolerance: 0.03549608043886109\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.179192585855375, tolerance: 0.03626193215054649\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.70742218950966, tolerance: 0.03529636127238454\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.889534045852415, tolerance: 0.03665926477813988\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.67856552469492, tolerance: 0.0360581125337969\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.80564256576288, tolerance: 0.03437248987207718\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.36361396814266, tolerance: 0.037226340219446256\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.21025912203265, tolerance: 0.03554984967608435\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.98304262555377, tolerance: 0.03408924626687752\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.79042794073868, tolerance: 0.036433101020153784\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.052715383413386, tolerance: 0.03286861928389535\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.19522432213607, tolerance: 0.035313941108011226\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.80664593755776, tolerance: 0.03608490683810065\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.97508741865617, tolerance: 0.028768221881032698\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.722449087876484, tolerance: 0.03222275600282619\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.78879899063499, tolerance: 0.034016501755988665\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.465366869668756, tolerance: 0.037847259752776474\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.51041912657205, tolerance: 0.03758771764694024\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.110862418650626, tolerance: 0.034804085452575524\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.55516227045405, tolerance: 0.032883238188863816\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.67389002739947, tolerance: 0.03265183442752774\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.74059379517874, tolerance: 0.035615711895399374\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.875336278067365, tolerance: 0.03599109935081621\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.86605506640604, tolerance: 0.03623420873654565\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.93058366623761, tolerance: 0.03725941329222018\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.641265432875414, tolerance: 0.035483843736890744\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.73687025515673, tolerance: 0.03509725703960038\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.82488715818403, tolerance: 0.0352178469186678\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.05114123325248, tolerance: 0.03229120989811719\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.62432246227369, tolerance: 0.036014711439349464\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.000515541259965, tolerance: 0.03892778846425829\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.88060734906971, tolerance: 0.035008864228021276\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.497849370343936, tolerance: 0.03542487140505466\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.79561327359239, tolerance: 0.034491362541195905\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.903497496527606, tolerance: 0.0354296357441266\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.78353603333352, tolerance: 0.037086684518170425\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.18254401047493, tolerance: 0.03244387899102625\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.034883709348094, tolerance: 0.03466713861167959\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.03373024161341, tolerance: 0.03432182551962572\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.504563522015104, tolerance: 0.03535442584336696\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.50295013578675, tolerance: 0.03694807417405576\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.31470632877897, tolerance: 0.03302087906794412\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.5299646209492, tolerance: 0.03674326983353731\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.70750647566153, tolerance: 0.035252897068346646\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.63924536751441, tolerance: 0.03610029008520341\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.98084987148374, tolerance: 0.036041253104518556\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.99062278154454, tolerance: 0.03715439505208706\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.294076659833735, tolerance: 0.03587408336183335\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.860498103324076, tolerance: 0.03748870639580023\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.7388210559359, tolerance: 0.03743783728853221\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.325071251203006, tolerance: 0.03293302278827033\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.388393520701456, tolerance: 0.03882622442014553\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.39683157664871, tolerance: 0.03916560842306134\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.32887495865482, tolerance: 0.036093389924848396\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.29143577101362, tolerance: 0.035981216910959526\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.89647356090451, tolerance: 0.03327902473187734\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Linear Regression with Lasso\n",
    "\n",
    "lr_test_acc = []\n",
    "lr_nonzero = []\n",
    "trial = 0\n",
    "lambdrange = np.arange(0,.6,.005)\n",
    "ntrials = 100\n",
    "\n",
    "for lambd in lambdrange:\n",
    "    trial = 0\n",
    "    while trial < ntrials:\n",
    "        xTrain, xTest, yTrain, yTest = sklearn.model_selection.train_test_split(X,y,test_size = .3)\n",
    "        lasso_mod = sklearn.linear_model.Lasso(alpha = lambd).fit(xTrain,yTrain)\n",
    "        pred = lasso_mod.predict(xTest)\n",
    "        test_error = np.sqrt(np.mean((yTest -pred)**2))\n",
    "        nonzero = len(np.where(lasso_mod.coef_ != 0)[0])\n",
    "        lr_test_acc.append(test_error)\n",
    "        lr_nonzero.append(nonzero)\n",
    "        trial = trial + 1\n",
    "        \n",
    "gc.collect()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tradeoff_curve(test_acc,nonzero,color,ntrials,label):\n",
    "    results = pd.DataFrame()\n",
    "    for i in range(0,len(test_acc)):\n",
    "        results = results.append(pd.DataFrame(np.column_stack((test_acc[i],nonzero[i])),columns = ['test_acc','nonzero']))\n",
    "    agg = results.groupby(['nonzero'], as_index=False).agg({'test_acc':['mean','std']})\n",
    "    #plt.figure(figsize=(16,10))\n",
    "    plt.plot(agg['nonzero'],agg['test_acc']['mean'],color = color,label = label)\n",
    "    plt.errorbar(agg['nonzero'],agg['test_acc']['mean'], 1.96*agg['test_acc']['std']/np.sqrt(ntrials),color = color)\n",
    "    plt.xlabel('Number of Nonzero Features')\n",
    "    plt.ylabel('Test Error')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16,10))\n",
    "\n",
    "#plot_tradeoff_curve(boost_acc1,boost_nonzero1,'red',20,'boosting')\n",
    "#plot_tradeoff_curve(bag_acc1,bag_nonzero1,'orange',20,'bagging')\n",
    "\n",
    "plot_tradeoff_curve(ebm_test_acc,ebm_nonzero,'green',20,'ebm')\n",
    "#plot_tradeoff_curve(lr_test_acc,lr_nonzero,'blue',100,'linear regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
